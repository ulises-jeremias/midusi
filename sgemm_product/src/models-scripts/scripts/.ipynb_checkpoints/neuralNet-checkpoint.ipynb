{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../../../data/train_data.csv').values\n",
    "data_test = pd.read_csv('../../../data/test_data.csv').values\n",
    "\n",
    "# Build X and y\n",
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "# Number of atributes in training data\n",
    "n_att = X_train.shape[1]\n",
    "\n",
    "# Neurons\n",
    "n_neurons_1 = 64\n",
    "n_neurons_2 = 32\n",
    "n_neurons_3 = 16\n",
    "n_neurons_4 = 8\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_att])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Hidden weights\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_att, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output weights\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (transpose!)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  1.0592743\n",
      "MSE Test:  1.0660504\n",
      "pred:  [[-0.3234374   0.17382315  0.09712128 ... -0.13358004 -0.16526338\n",
      "  -0.37379745]]\n",
      "MSE Train:  0.5461139\n",
      "MSE Test:  0.5478513\n",
      "pred:  [[ 0.6570781  -0.8622529   1.1124159  ... -0.70319843 -0.34705198\n",
      "   0.6080489 ]]\n",
      "MSE Train:  0.3072777\n",
      "MSE Test:  0.3095964\n",
      "pred:  [[ 1.3463215  -0.6667043   1.9744916  ... -0.46712708 -0.39534622\n",
      "   0.21268204]]\n",
      "MSE Train:  0.24831894\n",
      "MSE Test:  0.24860597\n",
      "pred:  [[ 1.2162095  -0.55525035  2.1146348  ... -0.42120698 -0.41669127\n",
      "   0.2018408 ]]\n",
      "MSE Train:  0.23248807\n",
      "MSE Test:  0.23206685\n",
      "pred:  [[ 1.212003   -0.5627587   2.2480745  ... -0.41310287 -0.4442713\n",
      "   0.21875274]]\n",
      "MSE Train:  0.22430788\n",
      "MSE Test:  0.2232037\n",
      "pred:  [[ 1.1826502  -0.56082124  2.199005   ... -0.4218385  -0.4783951\n",
      "   0.16151997]]\n",
      "MSE Train:  0.22666141\n",
      "MSE Test:  0.22649978\n",
      "pred:  [[ 1.374411   -0.4379376   2.3809922  ... -0.33795974 -0.39707586\n",
      "   0.29763216]]\n",
      "MSE Train:  0.22209933\n",
      "MSE Test:  0.22156942\n",
      "pred:  [[ 0.90008223 -0.49447647  1.9273973  ... -0.4109073  -0.5116125\n",
      "   0.04917761]]\n",
      "MSE Train:  0.21534708\n",
      "MSE Test:  0.21592516\n",
      "pred:  [[ 1.3655196  -0.47136927  2.4096427  ... -0.39042667 -0.469929\n",
      "   0.15418223]]\n",
      "MSE Train:  0.21081592\n",
      "MSE Test:  0.21081243\n",
      "pred:  [[ 1.0361383  -0.48644176  1.9514369  ... -0.39927283 -0.48211816\n",
      "   0.01651223]]\n",
      "MSE Train:  0.21498486\n",
      "MSE Test:  0.21555004\n",
      "pred:  [[ 0.94869    -0.55131495  2.0143294  ... -0.4755003  -0.5241637\n",
      "  -0.23902066]]\n",
      "MSE Train:  0.21006648\n",
      "MSE Test:  0.21027161\n",
      "pred:  [[ 1.0084624  -0.43723303  1.8624482  ... -0.3566071  -0.43745244\n",
      "  -0.2190454 ]]\n",
      "MSE Train:  0.2074799\n",
      "MSE Test:  0.20663516\n",
      "pred:  [[ 0.9636809  -0.4102995   1.8878402  ... -0.34742168 -0.42056745\n",
      "  -0.01532412]]\n",
      "MSE Train:  0.20570584\n",
      "MSE Test:  0.20536952\n",
      "pred:  [[ 1.0686692  -0.45907602  1.7860758  ... -0.3986527  -0.47598\n",
      "   0.09936464]]\n",
      "MSE Train:  0.20354691\n",
      "MSE Test:  0.20266071\n",
      "pred:  [[ 0.95895183 -0.46887672  1.708549   ... -0.43808123 -0.507032\n",
      "   0.07364765]]\n",
      "MSE Train:  0.20274517\n",
      "MSE Test:  0.20285721\n",
      "pred:  [[ 1.0762787  -0.43675503  1.9526627  ... -0.40512627 -0.47291088\n",
      "   0.00405896]]\n",
      "MSE Train:  0.20713198\n",
      "MSE Test:  0.2070811\n",
      "pred:  [[ 1.1437596  -0.42550895  2.0825863  ... -0.3957854  -0.4616248\n",
      "   0.07357875]]\n",
      "MSE Train:  0.20742111\n",
      "MSE Test:  0.20795086\n",
      "pred:  [[ 1.2036134  -0.38173872  1.5656495  ... -0.3739319  -0.4231485\n",
      "   0.0361357 ]]\n",
      "MSE Train:  0.20392068\n",
      "MSE Test:  0.20411512\n",
      "pred:  [[ 1.0208778  -0.40647355  1.5742158  ... -0.37757707 -0.42896393\n",
      "   0.13823728]]\n",
      "MSE Train:  0.20151438\n",
      "MSE Test:  0.20292124\n",
      "pred:  [[ 1.0874091  -0.4088413   1.7591053  ... -0.38534105 -0.43695217\n",
      "   0.08250757]]\n",
      "MSE Train:  0.20073774\n",
      "MSE Test:  0.20052165\n",
      "pred:  [[ 1.1557505  -0.41043282  1.9993243  ... -0.39343986 -0.43556958\n",
      "   0.06765905]]\n",
      "MSE Train:  0.20948552\n",
      "MSE Test:  0.2095145\n",
      "pred:  [[ 0.9681694  -0.42212066  1.4983872  ... -0.40044475 -0.44190726\n",
      "  -0.04316301]]\n",
      "MSE Train:  0.20151669\n",
      "MSE Test:  0.20039827\n",
      "pred:  [[ 1.0341763  -0.4329551   1.6584167  ... -0.39892557 -0.42770123\n",
      "   0.14414476]]\n",
      "MSE Train:  0.20480998\n",
      "MSE Test:  0.2034419\n",
      "pred:  [[ 1.1622952  -0.43228593  2.065821   ... -0.39778653 -0.432365\n",
      "   0.24931966]]\n",
      "MSE Train:  0.20323208\n",
      "MSE Test:  0.20338356\n",
      "pred:  [[ 0.98738027 -0.45844403  1.7069005  ... -0.441615   -0.44871676\n",
      "  -0.18417954]]\n",
      "MSE Train:  0.20011452\n",
      "MSE Test:  0.19948055\n",
      "pred:  [[ 1.0895481  -0.38334063  1.7287383  ... -0.35787666 -0.39461565\n",
      "   0.1723908 ]]\n",
      "MSE Train:  0.19777416\n",
      "MSE Test:  0.19713914\n",
      "pred:  [[ 0.99743485 -0.40840065  1.712841   ... -0.37796688 -0.41767636\n",
      "  -0.04382945]]\n",
      "MSE Train:  0.1992107\n",
      "MSE Test:  0.19970234\n",
      "pred:  [[ 9.5964783e-01 -4.1382986e-01  1.5547169e+00 ... -3.9325470e-01\n",
      "  -4.1892990e-01 -6.8952516e-04]]\n",
      "MSE Train:  0.20395957\n",
      "MSE Test:  0.20387527\n",
      "pred:  [[ 1.2120911  -0.36638832  2.0926492  ... -0.3583566  -0.39407405\n",
      "   0.11054119]]\n",
      "MSE Train:  0.20323312\n",
      "MSE Test:  0.20356108\n",
      "pred:  [[ 1.0415112  -0.3974317   1.5925564  ... -0.38298523 -0.40234616\n",
      "  -0.16234101]]\n",
      "MSE Train:  0.19864987\n",
      "MSE Test:  0.19858152\n",
      "pred:  [[ 9.8353654e-01 -4.1063923e-01  1.5478003e+00 ... -4.1157418e-01\n",
      "  -4.3500507e-01 -1.2762994e-03]]\n",
      "MSE Train:  0.1986084\n",
      "MSE Test:  0.19757666\n",
      "pred:  [[ 1.1288918  -0.36798844  1.6145021  ... -0.3514285  -0.40283826\n",
      "   0.09193018]]\n",
      "MSE Train:  0.19912222\n",
      "MSE Test:  0.19809389\n",
      "pred:  [[ 1.1740428  -0.41073042  1.635924   ... -0.39231634 -0.43347466\n",
      "   0.08990566]]\n",
      "MSE Train:  0.20128119\n",
      "MSE Test:  0.20275612\n",
      "pred:  [[ 1.1341318  -0.40414795  1.3506131  ... -0.38793305 -0.43081656\n",
      "   0.02134442]]\n",
      "MSE Train:  0.19892606\n",
      "MSE Test:  0.19920836\n",
      "pred:  [[ 1.1687499  -0.38325292  1.8218352  ... -0.36923683 -0.40845668\n",
      "   0.19215243]]\n",
      "MSE Train:  0.20069046\n",
      "MSE Test:  0.20003273\n",
      "pred:  [[ 1.2181424  -0.4021716   1.7986041  ... -0.3812176  -0.4228634\n",
      "   0.01503628]]\n",
      "MSE Train:  0.19530167\n",
      "MSE Test:  0.19526577\n",
      "pred:  [[ 1.101839   -0.38961324  1.6508515  ... -0.36966455 -0.41067263\n",
      "   0.01476777]]\n",
      "MSE Train:  0.19864622\n",
      "MSE Test:  0.19801818\n",
      "pred:  [[ 1.1345459  -0.43978974  1.9418416  ... -0.41609907 -0.43940565\n",
      "  -0.020324  ]]\n",
      "MSE Train:  0.19582818\n",
      "MSE Test:  0.19661748\n",
      "pred:  [[ 1.1405195  -0.41818267  1.5413511  ... -0.39546466 -0.43129998\n",
      "   0.06128548]]\n",
      "MSE Train:  0.19598044\n",
      "MSE Test:  0.19679396\n",
      "pred:  [[ 1.2157544  -0.3942238   1.8056474  ... -0.37343258 -0.41316035\n",
      "   0.07706712]]\n",
      "MSE Train:  0.19707394\n",
      "MSE Test:  0.19839677\n",
      "pred:  [[ 1.1475792  -0.40200412  1.5478612  ... -0.39124212 -0.41547355\n",
      "   0.05470021]]\n",
      "MSE Train:  0.19825621\n",
      "MSE Test:  0.19833398\n",
      "pred:  [[ 0.9953229  -0.40597117  1.5996811  ... -0.36523107 -0.41865215\n",
      "  -0.01321075]]\n",
      "MSE Train:  0.19940548\n",
      "MSE Test:  0.20005845\n",
      "pred:  [[ 1.1230543  -0.4175      1.6897997  ... -0.39986047 -0.41711769\n",
      "   0.0569145 ]]\n",
      "MSE Train:  0.19799012\n",
      "MSE Test:  0.1977708\n",
      "pred:  [[ 1.1973822  -0.46677303  1.7805758  ... -0.4535712  -0.4711362\n",
      "  -0.05727381]]\n",
      "MSE Train:  0.19459586\n",
      "MSE Test:  0.19311114\n",
      "pred:  [[ 1.1341919  -0.46113512  1.6962334  ... -0.43281516 -0.46866253\n",
      "  -0.00932961]]\n",
      "MSE Train:  0.19608094\n",
      "MSE Test:  0.19577615\n",
      "pred:  [[ 1.0090258  -0.44458237  1.7042803  ... -0.43147177 -0.44989184\n",
      "  -0.08426243]]\n",
      "MSE Train:  0.19596909\n",
      "MSE Test:  0.19623029\n",
      "pred:  [[ 0.9457739  -0.45570132  1.5766892  ... -0.42383003 -0.4544894\n",
      "  -0.1901854 ]]\n",
      "MSE Train:  0.19904193\n",
      "MSE Test:  0.200567\n",
      "pred:  [[ 1.2053514  -0.4279065   1.728813   ... -0.40511012 -0.4366266\n",
      "   0.05047282]]\n",
      "MSE Train:  0.19666731\n",
      "MSE Test:  0.1982763\n",
      "pred:  [[ 1.1377784  -0.45789576  1.6041259  ... -0.43130916 -0.46045983\n",
      "  -0.00775741]]\n",
      "MSE Train:  0.19475166\n",
      "MSE Test:  0.19455223\n",
      "pred:  [[ 0.93262637 -0.4276043   1.4372344  ... -0.39072615 -0.429226\n",
      "  -0.01650422]]\n",
      "MSE Train:  0.19467923\n",
      "MSE Test:  0.19416796\n",
      "pred:  [[ 1.2075025  -0.44762892  1.740807   ... -0.40331846 -0.4419235\n",
      "   0.0509094 ]]\n",
      "MSE Train:  0.19711904\n",
      "MSE Test:  0.19649509\n",
      "pred:  [[ 1.1130899  -0.4150694   1.8724144  ... -0.38693723 -0.40816075\n",
      "  -0.07272033]]\n",
      "MSE Train:  0.2012109\n",
      "MSE Test:  0.19979446\n",
      "pred:  [[ 1.1818261  -0.47685605  1.8464462  ... -0.44861722 -0.48878306\n",
      "   0.13591294]]\n",
      "MSE Train:  0.2022102\n",
      "MSE Test:  0.20327254\n",
      "pred:  [[ 1.0404521  -0.39498478  1.4750687  ... -0.38035852 -0.40780476\n",
      "   0.14156558]]\n",
      "MSE Train:  0.20296554\n",
      "MSE Test:  0.20488025\n",
      "pred:  [[ 1.2712812  -0.42855468  1.8953239  ... -0.39164704 -0.41625983\n",
      "   0.01964023]]\n",
      "MSE Train:  0.19569291\n",
      "MSE Test:  0.19662961\n",
      "pred:  [[ 1.1602587  -0.5084303   1.7829351  ... -0.43715253 -0.4841603\n",
      "   0.1075598 ]]\n",
      "MSE Train:  0.19559747\n",
      "MSE Test:  0.19646123\n",
      "pred:  [[ 1.1809144  -0.46077603  1.5842491  ... -0.4173293  -0.44743198\n",
      "   0.01740997]]\n",
      "MSE Train:  0.19394083\n",
      "MSE Test:  0.19592011\n",
      "pred:  [[ 1.1803995  -0.40473136  1.7799892  ... -0.36082205 -0.39752194\n",
      "  -0.06371421]]\n",
      "MSE Train:  0.19424762\n",
      "MSE Test:  0.19405207\n",
      "pred:  [[ 1.145637   -0.44174692  1.8454254  ... -0.4066605  -0.45006558\n",
      "   0.05770141]]\n",
      "MSE Train:  0.19465292\n",
      "MSE Test:  0.19532664\n",
      "pred:  [[ 1.142985   -0.41487265  1.5320866  ... -0.36924934 -0.40522814\n",
      "  -0.01200655]]\n",
      "MSE Train:  0.19565053\n",
      "MSE Test:  0.19656336\n",
      "pred:  [[ 0.917392   -0.41088533  1.5284877  ... -0.3680935  -0.41948217\n",
      "  -0.05895902]]\n",
      "MSE Train:  0.19392288\n",
      "MSE Test:  0.19472791\n",
      "pred:  [[ 1.11805    -0.42345005  1.5687684  ... -0.3783694  -0.43512052\n",
      "  -0.03645407]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.19354753\n",
      "MSE Test:  0.19363807\n",
      "pred:  [[ 1.1505497  -0.4144191   1.8904531  ... -0.38371494 -0.41806763\n",
      "   0.08569506]]\n",
      "MSE Train:  0.19404827\n",
      "MSE Test:  0.193556\n",
      "pred:  [[ 1.1725729  -0.4185229   1.8022859  ... -0.37142655 -0.41243526\n",
      "   0.00714397]]\n",
      "MSE Train:  0.19281006\n",
      "MSE Test:  0.19250235\n",
      "pred:  [[ 1.1085609  -0.47514966  1.6996619  ... -0.43174863 -0.45965272\n",
      "  -0.07014814]]\n",
      "MSE Train:  0.19703457\n",
      "MSE Test:  0.19698471\n",
      "pred:  [[ 0.95680743 -0.4249741   1.5064104  ... -0.39445034 -0.42209\n",
      "   0.03138808]]\n",
      "MSE Train:  0.1968685\n",
      "MSE Test:  0.19814622\n",
      "pred:  [[ 1.1190087  -0.46318945  1.3580064  ... -0.40931597 -0.43906498\n",
      "  -0.04471675]]\n",
      "MSE Train:  0.19246757\n",
      "MSE Test:  0.19222875\n",
      "pred:  [[ 1.0469271  -0.4615832   1.5781575  ... -0.43228906 -0.46542096\n",
      "   0.02403514]]\n",
      "MSE Train:  0.19562069\n",
      "MSE Test:  0.19544488\n",
      "pred:  [[ 1.2097228  -0.47894847  1.8130983  ... -0.43021727 -0.46509448\n",
      "   0.06905088]]\n",
      "MSE Train:  0.19306147\n",
      "MSE Test:  0.19372241\n",
      "pred:  [[ 1.1192708  -0.4540535   1.7721517  ... -0.39157665 -0.43372604\n",
      "  -0.03303742]]\n",
      "MSE Train:  0.19374311\n",
      "MSE Test:  0.19453594\n",
      "pred:  [[ 1.0436623  -0.4475848   1.5244006  ... -0.37136358 -0.43029076\n",
      "  -0.02736928]]\n",
      "MSE Train:  0.19314812\n",
      "MSE Test:  0.1937469\n",
      "pred:  [[ 1.1044791  -0.43855008  1.495882   ... -0.37322763 -0.43216088\n",
      "   0.00767404]]\n",
      "MSE Train:  0.19591962\n",
      "MSE Test:  0.19573173\n",
      "pred:  [[ 1.2997619  -0.5251815   1.8446393  ... -0.46649218 -0.49952337\n",
      "   0.11562155]]\n",
      "MSE Train:  0.19390032\n",
      "MSE Test:  0.1945595\n",
      "pred:  [[ 1.1469973  -0.4551341   1.9900414  ... -0.3867225  -0.4366002\n",
      "  -0.03674002]]\n",
      "MSE Train:  0.19551387\n",
      "MSE Test:  0.19515547\n",
      "pred:  [[ 1.0961565  -0.43786147  1.8288876  ... -0.40472913 -0.4441804\n",
      "  -0.01272008]]\n",
      "MSE Train:  0.19311136\n",
      "MSE Test:  0.1939412\n",
      "pred:  [[ 1.0377209  -0.46053421  1.592616   ... -0.40312693 -0.45580268\n",
      "  -0.11215167]]\n",
      "MSE Train:  0.19276832\n",
      "MSE Test:  0.19396684\n",
      "pred:  [[ 1.2008828  -0.4876569   1.852919   ... -0.4287422  -0.4710745\n",
      "   0.01012644]]\n",
      "MSE Train:  0.19471924\n",
      "MSE Test:  0.19533631\n",
      "pred:  [[ 1.2743008  -0.49211395  1.9497445  ... -0.44168395 -0.49197072\n",
      "   0.09039744]]\n",
      "MSE Train:  0.19259259\n",
      "MSE Test:  0.19415532\n",
      "pred:  [[ 1.1103967  -0.46003067  1.7142068  ... -0.40192917 -0.4620631\n",
      "  -0.01032344]]\n",
      "MSE Train:  0.20020296\n",
      "MSE Test:  0.20266166\n",
      "pred:  [[ 1.069855   -0.44966584  1.5985905  ... -0.37514636 -0.45611092\n",
      "   0.04229999]]\n",
      "MSE Train:  0.19575308\n",
      "MSE Test:  0.19752418\n",
      "pred:  [[ 1.1717839  -0.41146374  1.7497603  ... -0.32759824 -0.42113534\n",
      "   0.12713768]]\n",
      "MSE Train:  0.19231269\n",
      "MSE Test:  0.19271217\n",
      "pred:  [[ 1.2179785  -0.47893366  1.94538    ... -0.40994245 -0.4742684\n",
      "   0.08132312]]\n",
      "MSE Train:  0.19425108\n",
      "MSE Test:  0.19495603\n",
      "pred:  [[ 1.098465   -0.47739252  1.7104942  ... -0.40519512 -0.48341432\n",
      "  -0.03589768]]\n",
      "MSE Train:  0.19341305\n",
      "MSE Test:  0.1948886\n",
      "pred:  [[ 1.1386821  -0.42970026  1.7035856  ... -0.35848165 -0.4362448\n",
      "   0.03606115]]\n",
      "MSE Train:  0.19541757\n",
      "MSE Test:  0.19497903\n",
      "pred:  [[ 1.0386872  -0.42748696  1.6423442  ... -0.3587345  -0.4595636\n",
      "   0.07048628]]\n",
      "MSE Train:  0.1947709\n",
      "MSE Test:  0.19555813\n",
      "pred:  [[ 1.1526653  -0.4900697   1.6235625  ... -0.4074353  -0.49233878\n",
      "  -0.07865841]]\n",
      "MSE Train:  0.1934705\n",
      "MSE Test:  0.1935268\n",
      "pred:  [[ 0.9795968  -0.45374468  1.6256726  ... -0.38254303 -0.4598258\n",
      "  -0.04242442]]\n",
      "MSE Train:  0.19296004\n",
      "MSE Test:  0.19435178\n",
      "pred:  [[ 1.1704769  -0.4934538   1.8677068  ... -0.41945842 -0.49647677\n",
      "   0.03434426]]\n",
      "MSE Train:  0.19663918\n",
      "MSE Test:  0.19739808\n",
      "pred:  [[ 1.2207154  -0.48755768  1.9475029  ... -0.40027907 -0.49192426\n",
      "   0.10212019]]\n",
      "MSE Train:  0.19361524\n",
      "MSE Test:  0.19511554\n",
      "pred:  [[ 1.1662602  -0.46487373  1.7633805  ... -0.3764389  -0.45044672\n",
      "   0.00260175]]\n",
      "MSE Train:  0.19374152\n",
      "MSE Test:  0.1944743\n",
      "pred:  [[ 1.138142   -0.48444885  1.590756   ... -0.43462414 -0.5045076\n",
      "  -0.03151871]]\n",
      "MSE Train:  0.19649298\n",
      "MSE Test:  0.19804285\n",
      "pred:  [[ 1.2311759  -0.4805658   1.7927003  ... -0.41399288 -0.502177\n",
      "   0.0224937 ]]\n",
      "MSE Train:  0.19465269\n",
      "MSE Test:  0.19618207\n",
      "pred:  [[ 1.0751734  -0.4432803   1.7087715  ... -0.38030598 -0.46040636\n",
      "   0.00606701]]\n",
      "MSE Train:  0.19518681\n",
      "MSE Test:  0.196372\n",
      "pred:  [[ 1.2452086  -0.48058692  2.0337083  ... -0.4137332  -0.48916042\n",
      "   0.07214618]]\n",
      "MSE Train:  0.19146195\n",
      "MSE Test:  0.19195993\n",
      "pred:  [[ 1.2894354  -0.4644197   1.9257455  ... -0.39618945 -0.47205952\n",
      "   0.04296116]]\n",
      "MSE Train:  0.19774538\n",
      "MSE Test:  0.19887221\n",
      "pred:  [[ 1.2862341  -0.5048459   1.9219378  ... -0.4497172  -0.5140452\n",
      "   0.11029724]]\n",
      "MSE Train:  0.19412616\n",
      "MSE Test:  0.19584645\n",
      "pred:  [[ 1.2293527  -0.47712934  1.8243134  ... -0.4233443  -0.48874068\n",
      "   0.07256502]]\n",
      "MSE Train:  0.19284631\n",
      "MSE Test:  0.19528805\n",
      "pred:  [[ 1.1128856  -0.50210613  1.5328524  ... -0.4363279  -0.50245655\n",
      "  -0.10483394]]\n",
      "MSE Train:  0.19303237\n",
      "MSE Test:  0.1933468\n",
      "pred:  [[ 1.1534176  -0.41237998  1.8604829  ... -0.35328543 -0.4394831\n",
      "   0.07344808]]\n",
      "MSE Train:  0.19154772\n",
      "MSE Test:  0.192184\n",
      "pred:  [[ 1.1859404  -0.46353596  1.6707442  ... -0.39282876 -0.47159594\n",
      "  -0.08178002]]\n",
      "MSE Train:  0.1924847\n",
      "MSE Test:  0.1945153\n",
      "pred:  [[ 1.1118408  -0.4305729   1.5854837  ... -0.36780217 -0.4549415\n",
      "  -0.04017723]]\n",
      "MSE Train:  0.19202432\n",
      "MSE Test:  0.19297346\n",
      "pred:  [[ 1.1972371  -0.46425998  1.77255    ... -0.41918105 -0.4711513\n",
      "  -0.01436418]]\n",
      "MSE Train:  0.19248135\n",
      "MSE Test:  0.19399793\n",
      "pred:  [[ 1.1119139  -0.4521054   1.6861293  ... -0.38923362 -0.469219\n",
      "  -0.00183357]]\n",
      "MSE Train:  0.19384272\n",
      "MSE Test:  0.19383848\n",
      "pred:  [[ 1.1510341  -0.4657575   1.9228954  ... -0.41038018 -0.48251295\n",
      "   0.00848781]]\n",
      "MSE Train:  0.19525492\n",
      "MSE Test:  0.19670713\n",
      "pred:  [[ 1.2046766  -0.5081747   1.9823585  ... -0.45355353 -0.51206243\n",
      "  -0.12946478]]\n",
      "MSE Train:  0.19374923\n",
      "MSE Test:  0.19529113\n",
      "pred:  [[ 1.1861877  -0.46864182  1.9362993  ... -0.39031726 -0.46338546\n",
      "   0.03755434]]\n",
      "MSE Train:  0.19182181\n",
      "MSE Test:  0.19217397\n",
      "pred:  [[ 1.0972438  -0.46294883  1.7329307  ... -0.37815002 -0.4616927\n",
      "  -0.04366035]]\n",
      "MSE Train:  0.19241385\n",
      "MSE Test:  0.19377053\n",
      "pred:  [[ 1.1919116  -0.41951257  1.8718824  ... -0.36028564 -0.4446154\n",
      "  -0.05301893]]\n",
      "MSE Train:  0.19190694\n",
      "MSE Test:  0.19303384\n",
      "pred:  [[ 1.035104   -0.4738225   1.5173357  ... -0.41844973 -0.49235007\n",
      "  -0.10849782]]\n",
      "MSE Train:  0.1915855\n",
      "MSE Test:  0.19238491\n",
      "pred:  [[ 1.0390116  -0.47299266  1.493753   ... -0.41461116 -0.49348497\n",
      "  -0.0416133 ]]\n",
      "MSE Train:  0.19348787\n",
      "MSE Test:  0.195231\n",
      "pred:  [[ 1.1020315  -0.43045893  1.5557393  ... -0.3738432  -0.4426776\n",
      "   0.06586417]]\n",
      "MSE Train:  0.19140156\n",
      "MSE Test:  0.19227347\n",
      "pred:  [[ 1.1482229  -0.44650447  1.7777033  ... -0.41500252 -0.4787854\n",
      "   0.07004006]]\n",
      "MSE Train:  0.19247177\n",
      "MSE Test:  0.19362183\n",
      "pred:  [[ 1.1338053  -0.46404973  1.6986299  ... -0.4273885  -0.49270013\n",
      "   0.0524281 ]]\n",
      "MSE Train:  0.19070294\n",
      "MSE Test:  0.19091487\n",
      "pred:  [[ 1.1202806  -0.44548428  1.6035453  ... -0.4095881  -0.47409344\n",
      "   0.02294792]]\n",
      "MSE Train:  0.19243069\n",
      "MSE Test:  0.19270355\n",
      "pred:  [[ 1.1032364e+00 -4.3391305e-01  1.5169337e+00 ... -3.8667291e-01\n",
      "  -4.6093017e-01 -1.2296438e-04]]\n",
      "MSE Train:  0.19298357\n",
      "MSE Test:  0.19470125\n",
      "pred:  [[ 1.0518978  -0.42560974  1.627748   ... -0.38663223 -0.44512904\n",
      "   0.04810838]]\n",
      "MSE Train:  0.19331957\n",
      "MSE Test:  0.19422442\n",
      "pred:  [[ 0.9917133  -0.4275885   1.6361504  ... -0.37629855 -0.4511262\n",
      "  -0.04810843]]\n",
      "MSE Train:  0.1917402\n",
      "MSE Test:  0.1930719\n",
      "pred:  [[ 1.1608207  -0.43251014  1.8086874  ... -0.36253482 -0.44022995\n",
      "   0.02181368]]\n",
      "MSE Train:  0.19118178\n",
      "MSE Test:  0.19221462\n",
      "pred:  [[ 1.1966653  -0.48287305  1.9223373  ... -0.43835324 -0.4903922\n",
      "   0.04107103]]\n",
      "MSE Train:  0.1912754\n",
      "MSE Test:  0.19244437\n",
      "pred:  [[ 1.2289203  -0.46888024  1.9227947  ... -0.41466352 -0.48575997\n",
      "   0.0339767 ]]\n",
      "MSE Train:  0.19069786\n",
      "MSE Test:  0.19184312\n",
      "pred:  [[ 1.1830074  -0.45845133  1.8342081  ... -0.4152579  -0.47895262\n",
      "   0.02411857]]\n",
      "MSE Train:  0.19126183\n",
      "MSE Test:  0.19049901\n",
      "pred:  [[ 1.1478987  -0.47674885  1.6370444  ... -0.40834534 -0.48477367\n",
      "  -0.01304451]]\n",
      "MSE Train:  0.1914864\n",
      "MSE Test:  0.19117795\n",
      "pred:  [[ 1.2402456  -0.4564909   1.7807046  ... -0.39822417 -0.46166736\n",
      "   0.01844048]]\n",
      "MSE Train:  0.19249971\n",
      "MSE Test:  0.19366695\n",
      "pred:  [[ 1.2245202  -0.45890293  1.609788   ... -0.41861206 -0.46707267\n",
      "  -0.03408062]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.1941259\n",
      "MSE Test:  0.19577162\n",
      "pred:  [[ 1.3730271  -0.4569373   2.0411346  ... -0.39338574 -0.47911194\n",
      "   0.02051261]]\n",
      "MSE Train:  0.19211191\n",
      "MSE Test:  0.19316871\n",
      "pred:  [[ 1.1237667  -0.46759328  1.7998025  ... -0.39926216 -0.46292773\n",
      "  -0.03900246]]\n",
      "MSE Train:  0.19240613\n",
      "MSE Test:  0.19185564\n",
      "pred:  [[ 1.0035194  -0.46007943  1.7625703  ... -0.37961477 -0.45999998\n",
      "  -0.05367623]]\n",
      "MSE Train:  0.19219255\n",
      "MSE Test:  0.19307445\n",
      "pred:  [[ 1.1004422  -0.44445485  1.8597013  ... -0.40154994 -0.4597444\n",
      "  -0.03812589]]\n",
      "MSE Train:  0.19318831\n",
      "MSE Test:  0.19453794\n",
      "pred:  [[ 1.1072237  -0.4292491   1.8450484  ... -0.38188925 -0.44451216\n",
      "  -0.02677006]]\n",
      "MSE Train:  0.19234198\n",
      "MSE Test:  0.19358905\n",
      "pred:  [[ 1.1485505  -0.45012727  1.6596515  ... -0.39762393 -0.4592524\n",
      "   0.03209003]]\n",
      "MSE Train:  0.19502275\n",
      "MSE Test:  0.1968549\n",
      "pred:  [[ 1.1134601  -0.44868028  1.6803744  ... -0.40581247 -0.47767222\n",
      "  -0.04888088]]\n",
      "MSE Train:  0.1974565\n",
      "MSE Test:  0.19852224\n",
      "pred:  [[ 1.2781141  -0.47674018  2.1907594  ... -0.4205617  -0.48183423\n",
      "   0.11544929]]\n",
      "MSE Train:  0.19589573\n",
      "MSE Test:  0.19752608\n",
      "pred:  [[ 1.0826054  -0.42596936  1.6517606  ... -0.367081   -0.43105018\n",
      "  -0.08102997]]\n",
      "MSE Train:  0.19378798\n",
      "MSE Test:  0.19361427\n",
      "pred:  [[ 1.1915333  -0.46234024  1.8969585  ... -0.4058026  -0.4590144\n",
      "   0.01570148]]\n",
      "MSE Train:  0.1942335\n",
      "MSE Test:  0.1957462\n",
      "pred:  [[ 1.0527533  -0.4790593   1.57895    ... -0.43316254 -0.47248077\n",
      "  -0.04958902]]\n",
      "MSE Train:  0.19812262\n",
      "MSE Test:  0.19836482\n",
      "pred:  [[ 1.1940467  -0.49832433  1.9648043  ... -0.4457035  -0.49849987\n",
      "   0.01888473]]\n",
      "MSE Train:  0.19244349\n",
      "MSE Test:  0.19497561\n",
      "pred:  [[ 1.1525322  -0.45160225  1.7891263  ... -0.38566968 -0.4502736\n",
      "   0.04158253]]\n",
      "MSE Train:  0.19573735\n",
      "MSE Test:  0.19584952\n",
      "pred:  [[ 1.2504997  -0.51302016  1.8746496  ... -0.45064974 -0.49247757\n",
      "   0.12830141]]\n",
      "MSE Train:  0.19582143\n",
      "MSE Test:  0.1967309\n",
      "pred:  [[ 1.2558397  -0.4966557   1.9965765  ... -0.44386625 -0.48641655\n",
      "  -0.0308347 ]]\n",
      "MSE Train:  0.19391075\n",
      "MSE Test:  0.19559202\n",
      "pred:  [[ 1.0759754  -0.4552159   1.556279   ... -0.3812014  -0.4598978\n",
      "  -0.00298923]]\n",
      "MSE Train:  0.19860311\n",
      "MSE Test:  0.20066868\n",
      "pred:  [[ 1.025764   -0.41740838  1.634802   ... -0.33315614 -0.42159775\n",
      "  -0.02223431]]\n",
      "MSE Train:  0.19065432\n",
      "MSE Test:  0.19222298\n",
      "pred:  [[ 1.0468166  -0.4593441   1.5596447  ... -0.39796835 -0.46529114\n",
      "  -0.07146864]]\n",
      "MSE Train:  0.19171143\n",
      "MSE Test:  0.19248791\n",
      "pred:  [[ 1.0156024  -0.4441635   1.624254   ... -0.3828148  -0.45170218\n",
      "  -0.02913589]]\n",
      "MSE Train:  0.19149825\n",
      "MSE Test:  0.1927185\n",
      "pred:  [[ 1.1413609  -0.49596524  1.9495196  ... -0.43640694 -0.49720854\n",
      "  -0.00962188]]\n",
      "MSE Train:  0.1909001\n",
      "MSE Test:  0.19244021\n",
      "pred:  [[ 1.1017466  -0.48209018  1.8770392  ... -0.4226483  -0.48443323\n",
      "  -0.05004205]]\n",
      "MSE Train:  0.19164695\n",
      "MSE Test:  0.19270831\n",
      "pred:  [[ 1.2717131  -0.488461    2.0157118  ... -0.4439787  -0.47491536\n",
      "   0.04572547]]\n",
      "MSE Train:  0.19154303\n",
      "MSE Test:  0.1923303\n",
      "pred:  [[ 1.198134   -0.49980497  1.8140059  ... -0.44602478 -0.49811435\n",
      "   0.08341874]]\n",
      "MSE Train:  0.19185103\n",
      "MSE Test:  0.19278128\n",
      "pred:  [[ 1.1322901  -0.44798544  1.8874923  ... -0.37472787 -0.44034892\n",
      "   0.05182794]]\n",
      "MSE Train:  0.19545521\n",
      "MSE Test:  0.19611265\n",
      "pred:  [[ 1.2572817  -0.42375743  2.073076   ... -0.37416565 -0.44331926\n",
      "   0.08083002]]\n",
      "MSE Train:  0.19039322\n",
      "MSE Test:  0.19127232\n",
      "pred:  [[ 1.2742723  -0.4635576   1.9575344  ... -0.39690915 -0.46724457\n",
      "   0.04095244]]\n",
      "MSE Train:  0.18991435\n",
      "MSE Test:  0.19074844\n",
      "pred:  [[ 1.1192411  -0.45339084  1.7532927  ... -0.38356298 -0.4542447\n",
      "   0.03962291]]\n",
      "MSE Train:  0.19496302\n",
      "MSE Test:  0.19664466\n",
      "pred:  [[ 1.3082803  -0.48898524  2.0161104  ... -0.43985525 -0.48982617\n",
      "  -0.0090244 ]]\n",
      "MSE Train:  0.19966972\n",
      "MSE Test:  0.20269315\n",
      "pred:  [[ 0.95578146 -0.4481543   1.4096675  ... -0.39584276 -0.44198585\n",
      "  -0.06508964]]\n",
      "MSE Train:  0.1969942\n",
      "MSE Test:  0.1993108\n",
      "pred:  [[ 1.1125199  -0.40336856  1.7914846  ... -0.32641327 -0.43102568\n",
      "  -0.00552887]]\n",
      "MSE Train:  0.19432914\n",
      "MSE Test:  0.19517426\n",
      "pred:  [[ 1.2630494  -0.47850633  2.022129   ... -0.43955544 -0.48300064\n",
      "   0.03944103]]\n",
      "MSE Train:  0.19134837\n",
      "MSE Test:  0.19155496\n",
      "pred:  [[ 1.1464422  -0.4538959   1.7688694  ... -0.41035357 -0.47675908\n",
      "   0.05765778]]\n",
      "MSE Train:  0.19195144\n",
      "MSE Test:  0.19287293\n",
      "pred:  [[ 1.096627   -0.47467723  1.8250644  ... -0.43607917 -0.49226663\n",
      "  -0.02963229]]\n",
      "MSE Train:  0.19125342\n",
      "MSE Test:  0.1921295\n",
      "pred:  [[ 1.0688602  -0.4328779   1.7201332  ... -0.3885516  -0.44868708\n",
      "  -0.03982677]]\n",
      "MSE Train:  0.19000572\n",
      "MSE Test:  0.19071354\n",
      "pred:  [[ 1.1113356  -0.47286013  1.6970357  ... -0.42504227 -0.48138353\n",
      "  -0.08903401]]\n",
      "MSE Train:  0.19447887\n",
      "MSE Test:  0.1951268\n",
      "pred:  [[ 1.2396202  -0.50138885  1.8063486  ... -0.45524237 -0.50318295\n",
      "   0.01141054]]\n",
      "MSE Train:  0.19034311\n",
      "MSE Test:  0.19130416\n",
      "pred:  [[ 1.1079144  -0.46769914  1.6139386  ... -0.41312513 -0.47667846\n",
      "  -0.04739467]]\n",
      "MSE Train:  0.19181468\n",
      "MSE Test:  0.192263\n",
      "pred:  [[ 1.2098026  -0.4605939   2.0320864  ... -0.4261461  -0.48180088\n",
      "   0.04985958]]\n",
      "MSE Train:  0.19112913\n",
      "MSE Test:  0.19286507\n",
      "pred:  [[ 1.1832908e+00 -4.5664561e-01  1.9124211e+00 ... -4.1347855e-01\n",
      "  -4.6931988e-01 -1.6876012e-03]]\n",
      "MSE Train:  0.19033608\n",
      "MSE Test:  0.19167723\n",
      "pred:  [[ 1.1841772  -0.45642543  1.8573364  ... -0.4208549  -0.46960342\n",
      "   0.01240396]]\n",
      "MSE Train:  0.19217809\n",
      "MSE Test:  0.19258511\n",
      "pred:  [[ 1.2265736  -0.4747166   2.0519173  ... -0.43793693 -0.4851293\n",
      "   0.04406843]]\n",
      "MSE Train:  0.19120318\n",
      "MSE Test:  0.19106211\n",
      "pred:  [[ 1.26313    -0.44323     1.9394879  ... -0.4006646  -0.45689967\n",
      "   0.0797272 ]]\n",
      "MSE Train:  0.1908376\n",
      "MSE Test:  0.19124931\n",
      "pred:  [[ 1.2504783  -0.4587402   1.9700685  ... -0.42702246 -0.4635014\n",
      "   0.04751167]]\n",
      "MSE Train:  0.19083142\n",
      "MSE Test:  0.19216311\n",
      "pred:  [[ 1.0763994  -0.44581458  1.8098217  ... -0.39796287 -0.45322967\n",
      "   0.00601995]]\n",
      "MSE Train:  0.19809215\n",
      "MSE Test:  0.19670802\n",
      "pred:  [[ 1.2209641  -0.45206293  2.076444   ... -0.41640276 -0.47337106\n",
      "   0.00324411]]\n",
      "MSE Train:  0.19113986\n",
      "MSE Test:  0.19189402\n",
      "pred:  [[ 1.1898745  -0.42442027  1.8688649  ... -0.3972535  -0.44182032\n",
      "  -0.00707861]]\n",
      "MSE Train:  0.19139339\n",
      "MSE Test:  0.1922978\n",
      "pred:  [[ 1.0614929  -0.4417351   1.6613047  ... -0.41225976 -0.45310026\n",
      "   0.02178167]]\n",
      "MSE Train:  0.19423969\n",
      "MSE Test:  0.19519964\n",
      "pred:  [[ 0.95115244 -0.44895414  1.4913152  ... -0.40930876 -0.4611493\n",
      "   0.01448825]]\n",
      "MSE Train:  0.19714695\n",
      "MSE Test:  0.19961673\n",
      "pred:  [[ 1.0762885  -0.41219997  1.631556   ... -0.371951   -0.43300298\n",
      "  -0.05569604]]\n",
      "MSE Train:  0.19003552\n",
      "MSE Test:  0.19161439\n",
      "pred:  [[ 1.1399121  -0.44466808  1.8253785  ... -0.39411166 -0.4611605\n",
      "   0.06994601]]\n",
      "MSE Train:  0.18976569\n",
      "MSE Test:  0.19105168\n",
      "pred:  [[ 1.1298664  -0.45149478  1.6866053  ... -0.3922457  -0.46374285\n",
      "   0.05685722]]\n",
      "MSE Train:  0.19004387\n",
      "MSE Test:  0.19149174\n",
      "pred:  [[ 1.1572837  -0.45317212  1.7374092  ... -0.37815762 -0.46099377\n",
      "   0.0565111 ]]\n",
      "MSE Train:  0.19141619\n",
      "MSE Test:  0.19278313\n",
      "pred:  [[ 1.127469   -0.46452516  1.6786515  ... -0.39502522 -0.47272307\n",
      "   0.06815115]]\n",
      "MSE Train:  0.19352916\n",
      "MSE Test:  0.1934107\n",
      "pred:  [[ 1.2453684  -0.46136728  1.8874815  ... -0.41075498 -0.47393402\n",
      "   0.00320628]]\n",
      "MSE Train:  0.19985026\n",
      "MSE Test:  0.1987207\n",
      "pred:  [[ 1.2900155  -0.46865526  2.0515203  ... -0.43380973 -0.48124373\n",
      "   0.13030815]]\n",
      "MSE Train:  0.19037363\n",
      "MSE Test:  0.19163325\n",
      "pred:  [[ 1.148365   -0.47068322  1.7414863  ... -0.4241436  -0.47558725\n",
      "   0.00261515]]\n",
      "MSE Train:  0.19052361\n",
      "MSE Test:  0.19146827\n",
      "pred:  [[ 1.1145577  -0.45847097  1.8396232  ... -0.40327296 -0.4657899\n",
      "  -0.02937198]]\n",
      "MSE Train:  0.19031005\n",
      "MSE Test:  0.19114374\n",
      "pred:  [[ 1.0362158  -0.46198303  1.8449817  ... -0.42291635 -0.47933838\n",
      "  -0.08773234]]\n",
      "MSE Train:  0.19127409\n",
      "MSE Test:  0.19141935\n",
      "pred:  [[ 1.1998065  -0.43760502  1.9132466  ... -0.37751564 -0.4559604\n",
      "   0.05999713]]\n",
      "MSE Train:  0.1896683\n",
      "MSE Test:  0.18957593\n",
      "pred:  [[ 1.1237919  -0.45048404  1.7918072  ... -0.40512103 -0.4721173\n",
      "   0.01276813]]\n",
      "MSE Train:  0.19062264\n",
      "MSE Test:  0.1899071\n",
      "pred:  [[ 1.1326779  -0.43330735  1.8773133  ... -0.4017224  -0.45612893\n",
      "   0.0462591 ]]\n",
      "MSE Train:  0.1901169\n",
      "MSE Test:  0.19143575\n",
      "pred:  [[ 1.1749996  -0.45558754  1.7974163  ... -0.4059348  -0.44919315\n",
      "   0.0635426 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.19345088\n",
      "MSE Test:  0.19395055\n",
      "pred:  [[ 1.0742368  -0.45172113  1.875331   ... -0.4070353  -0.4632826\n",
      "   0.03978546]]\n",
      "MSE Train:  0.19560146\n",
      "MSE Test:  0.19803475\n",
      "pred:  [[ 1.0498893  -0.44907165  1.6693379  ... -0.41735893 -0.4638446\n",
      "  -0.00794189]]\n",
      "MSE Train:  0.19268279\n",
      "MSE Test:  0.19442709\n",
      "pred:  [[ 0.99976045 -0.43421447  1.6262766  ... -0.40339816 -0.44993287\n",
      "  -0.03241588]]\n",
      "MSE Train:  0.1919786\n",
      "MSE Test:  0.19280006\n",
      "pred:  [[ 1.0095283  -0.43886584  1.7636489  ... -0.39540815 -0.4650318\n",
      "  -0.08808385]]\n",
      "MSE Train:  0.19271907\n",
      "MSE Test:  0.19195141\n",
      "pred:  [[ 1.1049364  -0.43019426  1.7475185  ... -0.38828242 -0.46238053\n",
      "   0.02349944]]\n",
      "MSE Train:  0.19844599\n",
      "MSE Test:  0.19808818\n",
      "pred:  [[ 1.2941768  -0.4872681   2.059186   ... -0.4477257  -0.49295318\n",
      "   0.1080033 ]]\n",
      "MSE Train:  0.19228593\n",
      "MSE Test:  0.19253777\n",
      "pred:  [[ 1.1344397  -0.45907646  1.8801919  ... -0.42034745 -0.4696827\n",
      "   0.03221153]]\n",
      "MSE Train:  0.19137\n",
      "MSE Test:  0.19280744\n",
      "pred:  [[ 1.1438786  -0.44703653  1.8059214  ... -0.40064284 -0.45112857\n",
      "  -0.02308831]]\n",
      "MSE Train:  0.19381492\n",
      "MSE Test:  0.19522163\n",
      "pred:  [[ 0.9116614  -0.42918703  1.5295767  ... -0.3877402  -0.44199377\n",
      "  -0.12813091]]\n",
      "MSE Train:  0.19285119\n",
      "MSE Test:  0.19381976\n",
      "pred:  [[ 1.1235986  -0.448719    1.7333337  ... -0.40060002 -0.4687937\n",
      "  -0.07305104]]\n",
      "MSE Train:  0.19112803\n",
      "MSE Test:  0.19243592\n",
      "pred:  [[ 1.2330022  -0.47268498  1.8767827  ... -0.43961388 -0.4730807\n",
      "   0.07953523]]\n",
      "MSE Train:  0.18989313\n",
      "MSE Test:  0.19040327\n",
      "pred:  [[ 1.1433941  -0.46088302  1.8633637  ... -0.41573024 -0.46459132\n",
      "   0.03912126]]\n",
      "MSE Train:  0.19277425\n",
      "MSE Test:  0.19187501\n",
      "pred:  [[ 1.1694571  -0.50073606  1.9587362  ... -0.4580884  -0.49984503\n",
      "   0.0725842 ]]\n",
      "MSE Train:  0.18976602\n",
      "MSE Test:  0.19065653\n",
      "pred:  [[ 1.1409761  -0.45383283  1.8562496  ... -0.4019164  -0.46147707\n",
      "   0.08120441]]\n",
      "MSE Train:  0.19209716\n",
      "MSE Test:  0.19330125\n",
      "pred:  [[ 0.9937367  -0.4442861   1.5863657  ... -0.40679803 -0.47110438\n",
      "   0.044092  ]]\n",
      "MSE Train:  0.18966998\n",
      "MSE Test:  0.19011873\n",
      "pred:  [[ 1.1896222  -0.4491896   1.8939726  ... -0.4099275  -0.46363977\n",
      "   0.0313103 ]]\n",
      "MSE Train:  0.19140814\n",
      "MSE Test:  0.19209754\n",
      "pred:  [[ 1.1758298  -0.44029602  1.9263607  ... -0.38359573 -0.45824647\n",
      "  -0.0185931 ]]\n",
      "MSE Train:  0.19068266\n",
      "MSE Test:  0.19158858\n",
      "pred:  [[ 1.0532985  -0.44740847  1.7310191  ... -0.4113929  -0.46141148\n",
      "  -0.01656299]]\n",
      "MSE Train:  0.19048461\n",
      "MSE Test:  0.1919491\n",
      "pred:  [[ 1.1138259  -0.43604815  1.7504354  ... -0.39353156 -0.45172817\n",
      "  -0.01341192]]\n",
      "MSE Train:  0.19123161\n",
      "MSE Test:  0.19321932\n",
      "pred:  [[ 1.0593561  -0.46185333  1.604752   ... -0.41617954 -0.46801072\n",
      "   0.01614996]]\n",
      "MSE Train:  0.19055884\n",
      "MSE Test:  0.1902033\n",
      "pred:  [[ 1.1239648  -0.44584382  1.9690957  ... -0.39432082 -0.45430654\n",
      "   0.04451368]]\n",
      "MSE Train:  0.19003122\n",
      "MSE Test:  0.19010666\n",
      "pred:  [[ 1.116335   -0.47023204  1.7154604  ... -0.4241962  -0.47023037\n",
      "   0.04463079]]\n",
      "MSE Train:  0.18988696\n",
      "MSE Test:  0.190035\n",
      "pred:  [[ 1.0759058  -0.46545613  1.7208922  ... -0.4262275  -0.46851277\n",
      "   0.01907761]]\n",
      "MSE Train:  0.19520797\n",
      "MSE Test:  0.19418919\n",
      "pred:  [[ 1.2227212  -0.44744635  2.0001373  ... -0.40413487 -0.45876932\n",
      "   0.08261652]]\n",
      "MSE Train:  0.191422\n",
      "MSE Test:  0.1911511\n",
      "pred:  [[ 1.169139   -0.44210464  2.0011015  ... -0.3869152  -0.46123052\n",
      "   0.03135528]]\n",
      "MSE Train:  0.18973665\n",
      "MSE Test:  0.19046941\n",
      "pred:  [[ 1.1058806  -0.4477529   1.7724932  ... -0.40972823 -0.4541676\n",
      "   0.029442  ]]\n",
      "MSE Train:  0.19062775\n",
      "MSE Test:  0.1924919\n",
      "pred:  [[ 1.0645028  -0.439177    1.7759725  ... -0.4006498  -0.44716194\n",
      "  -0.0291132 ]]\n",
      "MSE Train:  0.19149865\n",
      "MSE Test:  0.19328399\n",
      "pred:  [[ 1.0581446  -0.45049158  1.8296057  ... -0.40211704 -0.44764104\n",
      "   0.05355545]]\n",
      "MSE Train:  0.19000632\n",
      "MSE Test:  0.19075099\n",
      "pred:  [[ 1.1205117  -0.46572664  1.7540594  ... -0.41041577 -0.45717698\n",
      "   0.08134455]]\n",
      "MSE Train:  0.19086857\n",
      "MSE Test:  0.19070025\n",
      "pred:  [[ 1.0460165  -0.4818428   1.8323247  ... -0.43369097 -0.48167077\n",
      "   0.04956157]]\n",
      "MSE Train:  0.19410205\n",
      "MSE Test:  0.1959558\n",
      "pred:  [[ 1.0475459  -0.4712696   1.5294263  ... -0.42405087 -0.47535577\n",
      "  -0.02405108]]\n",
      "MSE Train:  0.19087318\n",
      "MSE Test:  0.19143854\n",
      "pred:  [[ 1.1085877  -0.47935387  1.8264706  ... -0.41783962 -0.4711586\n",
      "   0.03176102]]\n",
      "MSE Train:  0.19101368\n",
      "MSE Test:  0.19108082\n",
      "pred:  [[ 1.0383687  -0.47615182  1.6849473  ... -0.41316995 -0.47099864\n",
      "   0.04364971]]\n",
      "MSE Train:  0.19182618\n",
      "MSE Test:  0.19126937\n",
      "pred:  [[ 1.0712959  -0.4724869   1.8360467  ... -0.42268777 -0.47521627\n",
      "  -0.01309967]]\n",
      "MSE Train:  0.19596711\n",
      "MSE Test:  0.19513117\n",
      "pred:  [[ 1.1960967  -0.48920617  1.8550911  ... -0.44391572 -0.47814515\n",
      "  -0.03132376]]\n",
      "MSE Train:  0.1896895\n",
      "MSE Test:  0.19077067\n",
      "pred:  [[ 1.1540706  -0.45996097  1.758771   ... -0.40422225 -0.4588809\n",
      "   0.06090182]]\n",
      "MSE Train:  0.19008288\n",
      "MSE Test:  0.19120958\n",
      "pred:  [[ 1.2617042  -0.4636695   1.8887048  ... -0.43105957 -0.47148308\n",
      "   0.08195806]]\n",
      "MSE Train:  0.1956058\n",
      "MSE Test:  0.19558\n",
      "pred:  [[ 1.2368675  -0.47337112  2.0999594  ... -0.4332006  -0.48163253\n",
      "   0.06923383]]\n",
      "MSE Train:  0.19299315\n",
      "MSE Test:  0.1932232\n",
      "pred:  [[ 1.1846982  -0.47060573  2.0483277  ... -0.4274162  -0.4805357\n",
      "   0.06105714]]\n",
      "MSE Train:  0.19525997\n",
      "MSE Test:  0.19520049\n",
      "pred:  [[ 1.2557189e+00 -4.9080729e-01  2.0300469e+00 ... -4.4584677e-01\n",
      "  -4.8857793e-01  8.3296746e-04]]\n",
      "MSE Train:  0.18974991\n",
      "MSE Test:  0.19065851\n",
      "pred:  [[ 1.0625528  -0.4680641   1.8794887  ... -0.41637626 -0.46528003\n",
      "  -0.0079495 ]]\n",
      "MSE Train:  0.19227715\n",
      "MSE Test:  0.19420502\n",
      "pred:  [[ 1.0545375  -0.47895366  1.6889465  ... -0.4295352  -0.48098147\n",
      "   0.01645474]]\n",
      "MSE Train:  0.1931732\n",
      "MSE Test:  0.19476028\n",
      "pred:  [[ 1.0715716  -0.46912244  1.6319792  ... -0.40570897 -0.47035652\n",
      "   0.09836587]]\n",
      "MSE Train:  0.19503386\n",
      "MSE Test:  0.1968959\n",
      "pred:  [[ 1.1101964  -0.48055     1.6286693  ... -0.42309138 -0.47721133\n",
      "   0.07380804]]\n",
      "MSE Train:  0.18985508\n",
      "MSE Test:  0.19132178\n",
      "pred:  [[ 1.2408528  -0.4763415   1.8910968  ... -0.42570165 -0.4842315\n",
      "   0.05621216]]\n",
      "MSE Train:  0.19124962\n",
      "MSE Test:  0.19237982\n",
      "pred:  [[ 1.0170482  -0.47039905  1.6766253  ... -0.41062883 -0.4717554\n",
      "   0.07574237]]\n",
      "MSE Train:  0.19112942\n",
      "MSE Test:  0.19219437\n",
      "pred:  [[ 1.1337225  -0.44531518  1.8073618  ... -0.38134575 -0.44392022\n",
      "  -0.07668123]]\n",
      "MSE Train:  0.19169082\n",
      "MSE Test:  0.19343594\n",
      "pred:  [[ 1.1713431  -0.48736998  1.8812876  ... -0.42979142 -0.48354095\n",
      "   0.0775508 ]]\n",
      "MSE Train:  0.19036044\n",
      "MSE Test:  0.19134936\n",
      "pred:  [[ 1.1368127  -0.51123387  1.8486581  ... -0.437796   -0.50060254\n",
      "  -0.03969319]]\n",
      "MSE Train:  0.19269371\n",
      "MSE Test:  0.19333993\n",
      "pred:  [[ 1.0088866  -0.45797184  1.4898502  ... -0.38545758 -0.47137973\n",
      "  -0.04472497]]\n",
      "MSE Train:  0.19688454\n",
      "MSE Test:  0.1982207\n",
      "pred:  [[ 0.93034714 -0.46447098  1.4890246  ... -0.4051653  -0.45905483\n",
      "  -0.06993426]]\n",
      "MSE Train:  0.19032536\n",
      "MSE Test:  0.19090621\n",
      "pred:  [[ 1.1270065  -0.46681926  1.9133878  ... -0.415582   -0.47254276\n",
      "  -0.03167909]]\n",
      "MSE Train:  0.1906664\n",
      "MSE Test:  0.19063753\n",
      "pred:  [[ 1.0488338  -0.4359658   1.7198272  ... -0.36515936 -0.44776583\n",
      "  -0.05783188]]\n",
      "MSE Train:  0.19073416\n",
      "MSE Test:  0.19109553\n",
      "pred:  [[ 1.1510608  -0.43903917  1.8011568  ... -0.37236202 -0.44714046\n",
      "   0.05272375]]\n",
      "MSE Train:  0.1903374\n",
      "MSE Test:  0.1906777\n",
      "pred:  [[ 1.1900175  -0.482693    1.8460145  ... -0.437742   -0.48564386\n",
      "   0.01538754]]\n",
      "MSE Train:  0.19371825\n",
      "MSE Test:  0.19594978\n",
      "pred:  [[ 1.0575128  -0.44684842  1.6963472  ... -0.3982368  -0.4565766\n",
      "  -0.08089411]]\n",
      "MSE Train:  0.19069488\n",
      "MSE Test:  0.19191794\n",
      "pred:  [[ 1.1345007  -0.4661914   1.822305   ... -0.41273603 -0.4623042\n",
      "   0.02626342]]\n",
      "MSE Train:  0.1924924\n",
      "MSE Test:  0.1920846\n",
      "pred:  [[ 1.1718352  -0.4708864   1.9004922  ... -0.4215613  -0.47796905\n",
      "  -0.00435896]]\n",
      "MSE Train:  0.18983018\n",
      "MSE Test:  0.19025946\n",
      "pred:  [[ 1.051256   -0.4490942   1.7856785  ... -0.3971307  -0.45639482\n",
      "   0.05260959]]\n",
      "MSE Train:  0.19118932\n",
      "MSE Test:  0.19235756\n",
      "pred:  [[ 1.207637   -0.4662024   1.8450104  ... -0.41405037 -0.46963733\n",
      "   0.06240749]]\n",
      "MSE Train:  0.19162953\n",
      "MSE Test:  0.19118917\n",
      "pred:  [[ 1.1563407  -0.47095633  2.012874   ... -0.42026848 -0.4749884\n",
      "  -0.02786683]]\n",
      "MSE Train:  0.1904801\n",
      "MSE Test:  0.1917129\n",
      "pred:  [[ 1.0547552  -0.45495915  1.8209391  ... -0.39824963 -0.45989558\n",
      "  -0.04229993]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.19191536\n",
      "MSE Test:  0.19288029\n",
      "pred:  [[ 1.028633   -0.43196025  1.9354571  ... -0.38333243 -0.4491323\n",
      "  -0.04248609]]\n",
      "MSE Train:  0.1896925\n",
      "MSE Test:  0.18994275\n",
      "pred:  [[ 1.2567092  -0.46681625  1.9442667  ... -0.41482008 -0.46613228\n",
      "   0.0575413 ]]\n",
      "MSE Train:  0.19081369\n",
      "MSE Test:  0.19152933\n",
      "pred:  [[ 1.2376566  -0.46418673  1.8407557  ... -0.3888173  -0.4584509\n",
      "   0.00976296]]\n",
      "MSE Train:  0.18908094\n",
      "MSE Test:  0.18993291\n",
      "pred:  [[ 1.1959764  -0.45300627  1.8718976  ... -0.40414786 -0.45116347\n",
      "   0.02569247]]\n",
      "MSE Train:  0.19130225\n",
      "MSE Test:  0.19344668\n",
      "pred:  [[ 1.2227073  -0.461125    1.9225317  ... -0.41000593 -0.46731958\n",
      "   0.05886634]]\n",
      "MSE Train:  0.18958193\n",
      "MSE Test:  0.19008887\n",
      "pred:  [[ 1.1387138  -0.47559178  1.8788956  ... -0.40968788 -0.4684779\n",
      "   0.00357948]]\n",
      "MSE Train:  0.18999371\n",
      "MSE Test:  0.19043656\n",
      "pred:  [[ 1.1195161  -0.47588408  1.7865012  ... -0.4175449  -0.47821444\n",
      "  -0.00767542]]\n",
      "MSE Train:  0.19143604\n",
      "MSE Test:  0.19250453\n",
      "pred:  [[ 1.0079155  -0.44636178  1.711607   ... -0.39463204 -0.45882207\n",
      "   0.01960582]]\n",
      "MSE Train:  0.1896343\n",
      "MSE Test:  0.18980123\n",
      "pred:  [[ 1.1211071  -0.45941192  1.8890789  ... -0.4105296  -0.46778107\n",
      "   0.07697456]]\n",
      "MSE Train:  0.1913419\n",
      "MSE Test:  0.19265142\n",
      "pred:  [[ 1.159055   -0.4773332   1.7346761  ... -0.4264937  -0.47934675\n",
      "   0.10742082]]\n",
      "MSE Train:  0.18949832\n",
      "MSE Test:  0.1899682\n",
      "pred:  [[ 1.0784562  -0.48627806  1.7452201  ... -0.42028928 -0.48007408\n",
      "  -0.0286772 ]]\n",
      "MSE Train:  0.18989524\n",
      "MSE Test:  0.19080658\n",
      "pred:  [[ 1.111401   -0.47649014  1.7926694  ... -0.41656548 -0.47664404\n",
      "  -0.00571845]]\n",
      "MSE Train:  0.18933566\n",
      "MSE Test:  0.19089323\n",
      "pred:  [[ 1.0958618  -0.4936639   1.8620286  ... -0.43507248 -0.4907711\n",
      "  -0.02073222]]\n",
      "MSE Train:  0.19119398\n",
      "MSE Test:  0.19209634\n",
      "pred:  [[ 1.1171021  -0.48019242  1.920424   ... -0.43208116 -0.48832017\n",
      "   0.04941815]]\n",
      "MSE Train:  0.19262764\n",
      "MSE Test:  0.19434439\n",
      "pred:  [[ 1.1983317  -0.46473402  1.90123    ... -0.4129601  -0.45809215\n",
      "   0.0527298 ]]\n",
      "MSE Train:  0.19061765\n",
      "MSE Test:  0.19150896\n",
      "pred:  [[ 1.1516947  -0.46008384  1.7702163  ... -0.4094493  -0.46893474\n",
      "   0.04816142]]\n",
      "MSE Train:  0.19106664\n",
      "MSE Test:  0.19119607\n",
      "pred:  [[ 1.1322098  -0.49072576  1.9624029  ... -0.43639702 -0.48963696\n",
      "  -0.06298258]]\n",
      "MSE Train:  0.1891139\n",
      "MSE Test:  0.1900883\n",
      "pred:  [[ 1.170236   -0.48535675  1.9863921  ... -0.43525136 -0.486858\n",
      "   0.01998757]]\n",
      "MSE Train:  0.19001117\n",
      "MSE Test:  0.19073288\n",
      "pred:  [[ 1.0990644  -0.47476006  1.7166306  ... -0.4115717  -0.4705122\n",
      "   0.00215323]]\n",
      "MSE Train:  0.19044493\n",
      "MSE Test:  0.19134384\n",
      "pred:  [[ 1.1341084  -0.45011204  1.81541    ... -0.39288303 -0.45951328\n",
      "  -0.03171703]]\n",
      "MSE Train:  0.19193742\n",
      "MSE Test:  0.19357175\n",
      "pred:  [[ 1.0007868  -0.47010508  1.6207337  ... -0.41191956 -0.47962025\n",
      "  -0.08830881]]\n",
      "MSE Train:  0.1905994\n",
      "MSE Test:  0.19047846\n",
      "pred:  [[ 1.0492601  -0.482908    1.7505068  ... -0.39022738 -0.4811465\n",
      "   0.00818784]]\n",
      "MSE Train:  0.18984525\n",
      "MSE Test:  0.19025151\n",
      "pred:  [[ 1.1551872  -0.4661577   1.709832   ... -0.40886393 -0.46789792\n",
      "  -0.01935513]]\n",
      "MSE Train:  0.19132642\n",
      "MSE Test:  0.1928066\n",
      "pred:  [[ 1.1104934  -0.46647435  1.7909036  ... -0.4046779  -0.47395703\n",
      "   0.00614989]]\n",
      "MSE Train:  0.19108178\n",
      "MSE Test:  0.19281091\n",
      "pred:  [[ 1.1173049  -0.45735383  1.7853382  ... -0.39744923 -0.4663044\n",
      "   0.02101102]]\n",
      "MSE Train:  0.1915052\n",
      "MSE Test:  0.19212222\n",
      "pred:  [[ 1.282322   -0.46983182  1.9974192  ... -0.4190734  -0.47409248\n",
      "   0.08527316]]\n",
      "MSE Train:  0.18942985\n",
      "MSE Test:  0.18948586\n",
      "pred:  [[ 1.1195742  -0.4827832   1.8265512  ... -0.41988623 -0.47902304\n",
      "   0.02770936]]\n",
      "MSE Train:  0.18973735\n",
      "MSE Test:  0.18999133\n",
      "pred:  [[ 1.1872603  -0.47880453  1.7070961  ... -0.41086274 -0.46919978\n",
      "   0.01278676]]\n",
      "MSE Train:  0.1908305\n",
      "MSE Test:  0.19196106\n",
      "pred:  [[ 1.1298326  -0.49096227  1.6856782  ... -0.44146597 -0.48967284\n",
      "   0.00253071]]\n",
      "MSE Train:  0.1907684\n",
      "MSE Test:  0.19188192\n",
      "pred:  [[ 1.0475626  -0.45979118  1.7317555  ... -0.41253617 -0.46993256\n",
      "   0.03540719]]\n",
      "MSE Train:  0.19048594\n",
      "MSE Test:  0.18952419\n",
      "pred:  [[ 1.0985249  -0.48058298  1.7953037  ... -0.3954373  -0.4727441\n",
      "  -0.02955714]]\n",
      "MSE Train:  0.19008622\n",
      "MSE Test:  0.19025078\n",
      "pred:  [[ 1.1265595  -0.48223752  1.7578707  ... -0.4220258  -0.47932318\n",
      "   0.02057789]]\n",
      "MSE Train:  0.18895122\n",
      "MSE Test:  0.1891953\n",
      "pred:  [[ 1.0053471  -0.4826088   1.7976007  ... -0.4164967  -0.476341\n",
      "   0.04359527]]\n",
      "MSE Train:  0.19195165\n",
      "MSE Test:  0.19287083\n",
      "pred:  [[ 0.9390506  -0.471718    1.6658487  ... -0.38735878 -0.4743925\n",
      "  -0.06305313]]\n",
      "MSE Train:  0.19098161\n",
      "MSE Test:  0.19261721\n",
      "pred:  [[ 1.1454054  -0.45767272  1.825851   ... -0.42379007 -0.46862394\n",
      "   0.00506041]]\n",
      "MSE Train:  0.19034442\n",
      "MSE Test:  0.19089654\n",
      "pred:  [[ 0.95165694 -0.45138305  1.8529865  ... -0.40669644 -0.4691928\n",
      "   0.04451447]]\n",
      "MSE Train:  0.18954994\n",
      "MSE Test:  0.19025107\n",
      "pred:  [[ 1.0722415  -0.45491874  1.9101193  ... -0.38275105 -0.47913384\n",
      "  -0.02414263]]\n",
      "MSE Train:  0.18998155\n",
      "MSE Test:  0.19142391\n",
      "pred:  [[ 1.0462068  -0.46469557  1.898697   ... -0.4230523  -0.47541296\n",
      "  -0.04845829]]\n",
      "MSE Train:  0.19388355\n",
      "MSE Test:  0.19448522\n",
      "pred:  [[ 1.2094866  -0.4615871   2.1628256  ... -0.42717636 -0.48223352\n",
      "   0.07260437]]\n",
      "MSE Train:  0.19065024\n",
      "MSE Test:  0.19231655\n",
      "pred:  [[ 1.0641724  -0.4538285   1.6899658  ... -0.3986945  -0.4650538\n",
      "  -0.02669305]]\n",
      "MSE Train:  0.18946198\n",
      "MSE Test:  0.19091591\n",
      "pred:  [[ 1.117089   -0.4884633   1.7434435  ... -0.43925068 -0.4915367\n",
      "  -0.00503   ]]\n",
      "MSE Train:  0.19000845\n",
      "MSE Test:  0.19147925\n",
      "pred:  [[ 1.0543988  -0.46215895  1.5958993  ... -0.4050983  -0.4703365\n",
      "  -0.04424759]]\n",
      "MSE Train:  0.19033736\n",
      "MSE Test:  0.19180003\n",
      "pred:  [[ 1.0743717  -0.453743    1.984039   ... -0.40450916 -0.46435514\n",
      "   0.06398299]]\n",
      "MSE Train:  0.19090612\n",
      "MSE Test:  0.19336359\n",
      "pred:  [[ 1.1095756  -0.49134555  1.8240482  ... -0.43402845 -0.4817882\n",
      "   0.02198253]]\n",
      "MSE Train:  0.18940915\n",
      "MSE Test:  0.19100766\n",
      "pred:  [[ 1.1993303  -0.47810137  1.8349397  ... -0.43071634 -0.4843207\n",
      "   0.03212462]]\n",
      "MSE Train:  0.1951532\n",
      "MSE Test:  0.1963876\n",
      "pred:  [[ 1.0425445  -0.44852287  1.6286489  ... -0.4004373  -0.46322662\n",
      "  -0.08163994]]\n",
      "MSE Train:  0.19044517\n",
      "MSE Test:  0.19062987\n",
      "pred:  [[ 1.2362835  -0.4617934   1.8871977  ... -0.41781837 -0.4768873\n",
      "   0.08923284]]\n",
      "MSE Train:  0.18972246\n",
      "MSE Test:  0.19028911\n",
      "pred:  [[ 1.0392822  -0.45508093  1.6628131  ... -0.39223284 -0.464713\n",
      "  -0.085784  ]]\n",
      "MSE Train:  0.19203724\n",
      "MSE Test:  0.19222137\n",
      "pred:  [[ 1.188912   -0.47563803  1.9226346  ... -0.42213446 -0.48356822\n",
      "   0.02611399]]\n",
      "MSE Train:  0.1891433\n",
      "MSE Test:  0.18930252\n",
      "pred:  [[ 1.0705574  -0.4788743   1.872504   ... -0.4240765  -0.47863767\n",
      "  -0.02311948]]\n",
      "MSE Train:  0.18996187\n",
      "MSE Test:  0.1894678\n",
      "pred:  [[ 1.1183707  -0.46026158  1.9821821  ... -0.38879615 -0.4624982\n",
      "  -0.04076536]]\n",
      "MSE Train:  0.18982114\n",
      "MSE Test:  0.19052027\n",
      "pred:  [[ 1.0803729e+00 -4.8433349e-01  1.8355856e+00 ... -4.3964398e-01\n",
      "  -4.8593399e-01  1.3368949e-03]]\n",
      "MSE Train:  0.19235848\n",
      "MSE Test:  0.19296159\n",
      "pred:  [[ 0.9757009  -0.46720117  1.6284349  ... -0.40129274 -0.47212914\n",
      "  -0.0203551 ]]\n",
      "MSE Train:  0.1911484\n",
      "MSE Test:  0.19205225\n",
      "pred:  [[ 0.99576163 -0.47482318  1.8084772  ... -0.41662446 -0.47394264\n",
      "  -0.07493228]]\n",
      "MSE Train:  0.18976101\n",
      "MSE Test:  0.19012427\n",
      "pred:  [[ 1.0182974  -0.4538821   1.7771629  ... -0.38190198 -0.4622264\n",
      "  -0.02075003]]\n",
      "MSE Train:  0.18999383\n",
      "MSE Test:  0.19065464\n",
      "pred:  [[ 1.2320021  -0.4869131   1.970631   ... -0.43712494 -0.47840488\n",
      "   0.06563273]]\n",
      "MSE Train:  0.19095694\n",
      "MSE Test:  0.19128692\n",
      "pred:  [[ 1.2243361  -0.47377658  2.0450528  ... -0.42756194 -0.4716185\n",
      "   0.04421721]]\n",
      "MSE Train:  0.18937892\n",
      "MSE Test:  0.18914297\n",
      "pred:  [[ 1.081393   -0.4763526   1.872664   ... -0.39180812 -0.46721345\n",
      "  -0.03104708]]\n",
      "MSE Train:  0.19030304\n",
      "MSE Test:  0.1914939\n",
      "pred:  [[ 1.2117053  -0.47721243  1.83419    ... -0.42502064 -0.4776395\n",
      "  -0.01694346]]\n",
      "MSE Train:  0.19358662\n",
      "MSE Test:  0.19535148\n",
      "pred:  [[ 1.1554128  -0.47278053  1.7413814  ... -0.39880925 -0.4742599\n",
      "   0.06876226]]\n",
      "MSE Train:  0.19022864\n",
      "MSE Test:  0.1905303\n",
      "pred:  [[ 1.2160953  -0.48813108  1.8772908  ... -0.43529528 -0.4829178\n",
      "   0.01122683]]\n",
      "MSE Train:  0.19079323\n",
      "MSE Test:  0.19075646\n",
      "pred:  [[ 1.1760893  -0.4877807   1.8144042  ... -0.43426436 -0.47182977\n",
      "   0.02127351]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.19254094\n",
      "MSE Test:  0.1928105\n",
      "pred:  [[ 1.167748   -0.46966803  2.0841413  ... -0.41729093 -0.4683144\n",
      "   0.03504446]]\n",
      "MSE Train:  0.19023633\n",
      "MSE Test:  0.18990855\n",
      "pred:  [[ 1.000949   -0.47426072  1.7262496  ... -0.40693933 -0.47376567\n",
      "  -0.03903156]]\n",
      "MSE Train:  0.19208026\n",
      "MSE Test:  0.19124681\n",
      "pred:  [[ 1.1151351  -0.47151116  1.9092754  ... -0.41782513 -0.47469482\n",
      "   0.03001041]]\n",
      "MSE Train:  0.18968672\n",
      "MSE Test:  0.18989278\n",
      "pred:  [[ 1.168149   -0.47285643  1.8308394  ... -0.41482586 -0.4736294\n",
      "   0.06038184]]\n",
      "MSE Train:  0.1920247\n",
      "MSE Test:  0.19312643\n",
      "pred:  [[ 1.2404317  -0.48795575  2.1028037  ... -0.42291093 -0.4800259\n",
      "   0.07563724]]\n",
      "MSE Train:  0.18976288\n",
      "MSE Test:  0.19162849\n",
      "pred:  [[ 1.1040694  -0.46885297  1.7251934  ... -0.41502324 -0.47288257\n",
      "  -0.02250733]]\n",
      "MSE Train:  0.19320424\n",
      "MSE Test:  0.19438547\n",
      "pred:  [[ 1.1572906  -0.4654306   1.9025236  ... -0.41398573 -0.47277227\n",
      "   0.01353946]]\n",
      "MSE Train:  0.18927474\n",
      "MSE Test:  0.19071862\n",
      "pred:  [[ 1.050334   -0.4899992   1.8399346  ... -0.43446496 -0.48034355\n",
      "   0.02094642]]\n",
      "MSE Train:  0.19486621\n",
      "MSE Test:  0.19546036\n",
      "pred:  [[ 1.1183636  -0.46430695  2.2886221  ... -0.4144109  -0.47520542\n",
      "   0.06932218]]\n",
      "MSE Train:  0.18941773\n",
      "MSE Test:  0.18927626\n",
      "pred:  [[ 1.0917499  -0.47525626  1.6937606  ... -0.40008205 -0.4685113\n",
      "  -0.03265197]]\n",
      "Model saved in path: ../models/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Init\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit neural net\n",
    "    batch_size = 256\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "\n",
    "    # Run\n",
    "    epochs = 20\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        # Minibatch training\n",
    "        for i in range(0, len(y_train) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "            # Run optimizer with batch\n",
    "            sess.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "            # Show progress\n",
    "            if np.mod(i, 50) == 0:\n",
    "                # MSE train and test\n",
    "                mse_train.append(sess.run(mse, feed_dict={X: X_train, Y: y_train}))\n",
    "                mse_test.append(sess.run(mse, feed_dict={X: X_test, Y: y_test}))\n",
    "                print('MSE Train: ', mse_train[-1])\n",
    "                print('MSE Test: ', mse_test[-1])\n",
    "                # Prediction\n",
    "                pred = sess.run(out, feed_dict={X: X_test})\n",
    "                print('pred: ', pred)\n",
    "    save_path = saver.save(sess, \"../models/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
