{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaler\n",
    "scaler = joblib.load(\"../models/scaler.save\")\n",
    "\n",
    "MWG_NWG_configurations = [64, 128]\n",
    "KWG_configurations = [16, 32]\n",
    "MDIMC_NDIMC_configurations = [8, 16, 32]\n",
    "MDIMA_NDIMB_configurations = [8, 16, 32]\n",
    "KWI_configurations = [2, 8]\n",
    "VWM_VWN_configurations = [1, 2, 4, 8]\n",
    "STRM_STRN_configurations = [0, 1]\n",
    "SA_SB_configurations = [0, 1]\n",
    "\n",
    "configurations = np.array([]).reshape(0,15)\n",
    "for MWG_NWG_configuration in MWG_NWG_configurations:\n",
    "    for KWG_configuration in KWG_configurations:\n",
    "        for MDIMC_NDIMC_configuration in MDIMC_NDIMC_configurations:\n",
    "            for MDIMA_NDIMB_configuration in MDIMA_NDIMB_configurations:\n",
    "                for KWI_configuration in KWI_configurations:\n",
    "                    for VWM_VWN_configuration in VWM_VWN_configurations:\n",
    "                        for STRM_STRN_configuration in STRM_STRN_configurations:\n",
    "                            for SA_SB_configuration in SA_SB_configurations:\n",
    "                                configurations = np.vstack([configurations, [MWG_NWG_configuration, MWG_NWG_configuration, \n",
    "                                                                            KWG_configuration, MDIMC_NDIMC_configuration, \n",
    "                                                                            MDIMC_NDIMC_configuration, \n",
    "                                                                            MDIMA_NDIMB_configuration, \n",
    "                                                                            MDIMA_NDIMB_configuration, KWI_configuration, \n",
    "                                                                            VWM_VWN_configuration, VWM_VWN_configuration, \n",
    "                                                                            STRM_STRN_configuration, \n",
    "                                                                            STRM_STRN_configuration,\n",
    "                                                                            SA_SB_configuration,\n",
    "                                                                            SA_SB_configuration,0]])\n",
    "normalized_configurations = scaler.transform(configurations)[:,:-1]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Number of atributes in training data\n",
    "n_att = normalized_configurations.shape[1]\n",
    "\n",
    "# Neurons\n",
    "n_neurons_1 = 256\n",
    "n_neurons_2 = 128\n",
    "n_neurons_3 = 64\n",
    "n_neurons_4 = 32\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_att])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Hidden weights\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_att, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output weights\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (transpose!)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/model.ckpt\n",
      "Model restored.\n",
      "Best configuration:\n",
      "[128. 128.  32.  32.  32.  32.  32.   2.   4.   4.   1.   1.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"../models/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    pred = sess.run(out, feed_dict={X: normalized_configurations})\n",
    "    # print min prediction\n",
    "    print(\"Best configuration:\")\n",
    "    print(configurations[pred.argmin()][:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
