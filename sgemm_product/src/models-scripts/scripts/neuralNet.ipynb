{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('../../../data/train_data.csv').values\n",
    "data_test = pd.read_csv('../../../data/test_data.csv').values\n",
    "\n",
    "print(data_train.shape[1])\n",
    "\n",
    "# Build X and y\n",
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "# Number of atributes in training data\n",
    "n_att = X_train.shape[1]\n",
    "\n",
    "# Neurons\n",
    "n_neurons_1 = 256\n",
    "n_neurons_2 = 128\n",
    "n_neurons_3 = 64\n",
    "n_neurons_4 = 32\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_att])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Hidden weights\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_att, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output weights\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (transpose!)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.9795074\n",
      "MSE Test:  0.97684836\n",
      "pred:  [[ 0.05059671 -0.04411414 -0.03971947 ...  0.11060814  0.09584098\n",
      "   0.01097042]]\n",
      "MSE Train:  0.10879886\n",
      "MSE Test:  0.10997727\n",
      "pred:  [[-0.18895778 -0.5180253  -0.45053053 ... -0.34976786 -0.28672057\n",
      "   3.3590546 ]]\n",
      "MSE Train:  0.06164637\n",
      "MSE Test:  0.06288805\n",
      "pred:  [[-0.33265814 -0.3220619  -0.31529674 ... -0.5123952  -0.323401\n",
      "   3.447411  ]]\n",
      "MSE Train:  0.04403743\n",
      "MSE Test:  0.04430341\n",
      "pred:  [[-0.44569558 -0.31615597 -0.31244007 ... -0.48193043 -0.36472607\n",
      "   3.466197  ]]\n",
      "MSE Train:  0.04806081\n",
      "MSE Test:  0.04755624\n",
      "pred:  [[-0.48032108 -0.3898917  -0.38311395 ... -0.5185114  -0.4059641\n",
      "   3.112692  ]]\n",
      "MSE Train:  0.023989895\n",
      "MSE Test:  0.024401754\n",
      "pred:  [[-0.5093992  -0.39831766 -0.40550983 ... -0.52957773 -0.43369472\n",
      "   3.3342924 ]]\n",
      "MSE Train:  0.025936136\n",
      "MSE Test:  0.026453778\n",
      "pred:  [[-0.5321434  -0.36096594 -0.39532268 ... -0.47114244 -0.3910291\n",
      "   2.940453  ]]\n",
      "MSE Train:  0.016634205\n",
      "MSE Test:  0.017131737\n",
      "pred:  [[-0.49848065 -0.3170352  -0.35694522 ... -0.46230245 -0.3645648\n",
      "   3.4184027 ]]\n",
      "MSE Train:  0.012609838\n",
      "MSE Test:  0.013017541\n",
      "pred:  [[-0.52070177 -0.33966962 -0.3801207  ... -0.45464063 -0.414535\n",
      "   3.6099322 ]]\n",
      "MSE Train:  0.012736972\n",
      "MSE Test:  0.012825632\n",
      "pred:  [[-0.49224117 -0.37632936 -0.42423743 ... -0.49571693 -0.42893618\n",
      "   3.2425823 ]]\n",
      "MSE Train:  0.011465199\n",
      "MSE Test:  0.011598992\n",
      "pred:  [[-0.5287635  -0.359395   -0.41574126 ... -0.46038958 -0.3671257\n",
      "   3.514206  ]]\n",
      "MSE Train:  0.010897218\n",
      "MSE Test:  0.011177492\n",
      "pred:  [[-0.5350807  -0.3502692  -0.4064021  ... -0.48792997 -0.44778654\n",
      "   3.7874599 ]]\n",
      "MSE Train:  0.010522811\n",
      "MSE Test:  0.010882591\n",
      "pred:  [[-0.5111684  -0.28968325 -0.35430342 ... -0.39120823 -0.39667296\n",
      "   3.443803  ]]\n",
      "MSE Train:  0.009070853\n",
      "MSE Test:  0.009525019\n",
      "pred:  [[-0.53039056 -0.36055183 -0.3961166  ... -0.43661946 -0.4349307\n",
      "   3.526749  ]]\n",
      "MSE Train:  0.008549577\n",
      "MSE Test:  0.008610034\n",
      "pred:  [[-0.5678889  -0.38089612 -0.4307217  ... -0.4803741  -0.44827685\n",
      "   3.7404706 ]]\n",
      "MSE Train:  0.008102303\n",
      "MSE Test:  0.008318852\n",
      "pred:  [[-0.5259957  -0.34077343 -0.3815532  ... -0.44469213 -0.41446987\n",
      "   3.5603576 ]]\n",
      "MSE Train:  0.007769843\n",
      "MSE Test:  0.007956303\n",
      "pred:  [[-0.5292131  -0.3366087  -0.38241082 ... -0.44311136 -0.40936154\n",
      "   3.421028  ]]\n",
      "MSE Train:  0.006841504\n",
      "MSE Test:  0.007186574\n",
      "pred:  [[-0.52529734 -0.31045866 -0.37422758 ... -0.45806286 -0.42304537\n",
      "   3.3602839 ]]\n",
      "MSE Train:  0.006788099\n",
      "MSE Test:  0.0070091537\n",
      "pred:  [[-0.5337007  -0.3564074  -0.41007313 ... -0.48390597 -0.4600781\n",
      "   3.5717008 ]]\n",
      "MSE Train:  0.0067891334\n",
      "MSE Test:  0.0069005867\n",
      "pred:  [[-0.52586436 -0.3689162  -0.4045831  ... -0.46185035 -0.42594266\n",
      "   3.6764655 ]]\n",
      "MSE Train:  0.011006886\n",
      "MSE Test:  0.011318182\n",
      "pred:  [[-0.5278418  -0.39829144 -0.4453887  ... -0.45870072 -0.43579406\n",
      "   3.7527003 ]]\n",
      "MSE Train:  0.0063285194\n",
      "MSE Test:  0.0064272634\n",
      "pred:  [[-0.51832604 -0.35883394 -0.4067553  ... -0.44506234 -0.4055613\n",
      "   3.8396173 ]]\n",
      "MSE Train:  0.006411339\n",
      "MSE Test:  0.006555825\n",
      "pred:  [[-0.50950617 -0.38593623 -0.43416068 ... -0.44312736 -0.43872914\n",
      "   3.4709861 ]]\n",
      "MSE Train:  0.0069017936\n",
      "MSE Test:  0.0071944334\n",
      "pred:  [[-0.5003699  -0.3124337  -0.37760863 ... -0.42130303 -0.39239988\n",
      "   3.488793  ]]\n",
      "MSE Train:  0.0064644283\n",
      "MSE Test:  0.006695882\n",
      "pred:  [[-0.50461036 -0.3702993  -0.42933795 ... -0.466167   -0.4411675\n",
      "   3.5936878 ]]\n",
      "MSE Train:  0.0052707433\n",
      "MSE Test:  0.005608776\n",
      "pred:  [[-0.5103203  -0.36463952 -0.41076365 ... -0.41613075 -0.42281157\n",
      "   3.6472898 ]]\n",
      "MSE Train:  0.005426921\n",
      "MSE Test:  0.005711548\n",
      "pred:  [[-0.48210958 -0.33350354 -0.39504603 ... -0.39941004 -0.39998427\n",
      "   3.587457  ]]\n",
      "MSE Train:  0.005321716\n",
      "MSE Test:  0.005643737\n",
      "pred:  [[-0.51016587 -0.36914918 -0.41815463 ... -0.4286876  -0.42830107\n",
      "   3.4065742 ]]\n",
      "MSE Train:  0.0051841494\n",
      "MSE Test:  0.005441582\n",
      "pred:  [[-0.4931459  -0.3554574  -0.42654327 ... -0.4016362  -0.38219738\n",
      "   3.4326105 ]]\n",
      "MSE Train:  0.004890188\n",
      "MSE Test:  0.0051324735\n",
      "pred:  [[-0.47997296 -0.34449148 -0.42209518 ... -0.40920538 -0.41100746\n",
      "   3.7487757 ]]\n",
      "MSE Train:  0.0055258614\n",
      "MSE Test:  0.0058751246\n",
      "pred:  [[-0.49785513 -0.33695358 -0.40853006 ... -0.43011415 -0.42858285\n",
      "   3.6888106 ]]\n",
      "MSE Train:  0.0046836836\n",
      "MSE Test:  0.004976531\n",
      "pred:  [[-0.504369   -0.3668853  -0.4307906  ... -0.43252406 -0.42164636\n",
      "   3.611558  ]]\n",
      "MSE Train:  0.0050695585\n",
      "MSE Test:  0.0054126997\n",
      "pred:  [[-0.49811232 -0.37723297 -0.43639758 ... -0.4385364  -0.42422456\n",
      "   3.440182  ]]\n",
      "MSE Train:  0.005338933\n",
      "MSE Test:  0.0056285793\n",
      "pred:  [[-0.47593603 -0.31009865 -0.40122488 ... -0.40685076 -0.3801115\n",
      "   3.5243096 ]]\n",
      "MSE Train:  0.004887248\n",
      "MSE Test:  0.0052730716\n",
      "pred:  [[-0.502169   -0.32112598 -0.40153226 ... -0.40342018 -0.39736456\n",
      "   3.5279112 ]]\n",
      "MSE Train:  0.0045920056\n",
      "MSE Test:  0.004837591\n",
      "pred:  [[-0.5007533  -0.3565313  -0.43363944 ... -0.4339338  -0.40916377\n",
      "   3.8663888 ]]\n",
      "MSE Train:  0.0046269433\n",
      "MSE Test:  0.0048397384\n",
      "pred:  [[-0.4969629  -0.3705876  -0.44806105 ... -0.40179485 -0.396931\n",
      "   3.6455972 ]]\n",
      "MSE Train:  0.004537262\n",
      "MSE Test:  0.0047028703\n",
      "pred:  [[-0.523104   -0.38236102 -0.4572553  ... -0.4421532  -0.4460462\n",
      "   3.6779873 ]]\n",
      "MSE Train:  0.0047830865\n",
      "MSE Test:  0.005216344\n",
      "pred:  [[-0.49892953 -0.35367194 -0.42552578 ... -0.42233106 -0.4051068\n",
      "   3.484393  ]]\n",
      "MSE Train:  0.0053519197\n",
      "MSE Test:  0.0057903314\n",
      "pred:  [[-0.50463504 -0.34812826 -0.4258795  ... -0.44936112 -0.4421809\n",
      "   3.4166608 ]]\n",
      "MSE Train:  0.0052948073\n",
      "MSE Test:  0.005611771\n",
      "pred:  [[-0.52950776 -0.42979378 -0.46782357 ... -0.45356682 -0.42263284\n",
      "   3.568123  ]]\n",
      "MSE Train:  0.0038285302\n",
      "MSE Test:  0.004122162\n",
      "pred:  [[-0.5136095  -0.37407947 -0.4344921  ... -0.46809116 -0.40648106\n",
      "   3.6343443 ]]\n",
      "MSE Train:  0.004393317\n",
      "MSE Test:  0.0046503725\n",
      "pred:  [[-0.51007485 -0.33928302 -0.41334257 ... -0.43346345 -0.3894611\n",
      "   3.6102302 ]]\n",
      "MSE Train:  0.0039146557\n",
      "MSE Test:  0.0041790097\n",
      "pred:  [[-0.5156702  -0.35658333 -0.43216544 ... -0.4366188  -0.3946778\n",
      "   3.7808504 ]]\n",
      "MSE Train:  0.0053730174\n",
      "MSE Test:  0.005583931\n",
      "pred:  [[-0.51866865 -0.4010472  -0.4601619  ... -0.43696418 -0.42496875\n",
      "   3.7262871 ]]\n",
      "MSE Train:  0.0037808311\n",
      "MSE Test:  0.004105847\n",
      "pred:  [[-0.51398385 -0.3459051  -0.40644297 ... -0.4430956  -0.38834876\n",
      "   3.6859846 ]]\n",
      "MSE Train:  0.004489533\n",
      "MSE Test:  0.004718784\n",
      "pred:  [[-0.508764   -0.3948578  -0.46485573 ... -0.45222008 -0.41171846\n",
      "   3.8632667 ]]\n",
      "MSE Train:  0.0040745153\n",
      "MSE Test:  0.004285103\n",
      "pred:  [[-0.501954   -0.3493887  -0.42762953 ... -0.42113766 -0.40257332\n",
      "   3.8048313 ]]\n",
      "MSE Train:  0.0043062023\n",
      "MSE Test:  0.0045531825\n",
      "pred:  [[-0.5021016  -0.33772105 -0.41696274 ... -0.406807   -0.3939036\n",
      "   3.8434234 ]]\n",
      "MSE Train:  0.004389946\n",
      "MSE Test:  0.0047421744\n",
      "pred:  [[-0.5074884  -0.3870195  -0.4488553  ... -0.43493223 -0.4262143\n",
      "   3.6512053 ]]\n",
      "MSE Train:  0.0069201235\n",
      "MSE Test:  0.007075755\n",
      "pred:  [[-0.5150753  -0.3654009  -0.4314476  ... -0.43851712 -0.3990153\n",
      "   4.0262136 ]]\n",
      "MSE Train:  0.0041234815\n",
      "MSE Test:  0.0045020636\n",
      "pred:  [[-0.52356315 -0.39241484 -0.45610324 ... -0.44248524 -0.4118987\n",
      "   3.506362  ]]\n",
      "MSE Train:  0.0034611064\n",
      "MSE Test:  0.003744243\n",
      "pred:  [[-0.51427186 -0.3444247  -0.42245677 ... -0.43846595 -0.41258717\n",
      "   3.72857   ]]\n",
      "MSE Train:  0.004593363\n",
      "MSE Test:  0.004780778\n",
      "pred:  [[-0.5214396  -0.36581337 -0.4223449  ... -0.4440635  -0.42146805\n",
      "   3.6368017 ]]\n",
      "MSE Train:  0.0040013758\n",
      "MSE Test:  0.004204395\n",
      "pred:  [[-0.53589    -0.34513456 -0.42476726 ... -0.41251814 -0.38457003\n",
      "   3.6504183 ]]\n",
      "MSE Train:  0.0036554886\n",
      "MSE Test:  0.003874076\n",
      "pred:  [[-0.5153963  -0.3873407  -0.45720264 ... -0.44278815 -0.4035937\n",
      "   3.6776333 ]]\n",
      "MSE Train:  0.003518276\n",
      "MSE Test:  0.0037616293\n",
      "pred:  [[-0.50804245 -0.3502611  -0.42565167 ... -0.4294571  -0.38400665\n",
      "   3.6571562 ]]\n",
      "MSE Train:  0.0037086322\n",
      "MSE Test:  0.004002441\n",
      "pred:  [[-0.50146395 -0.3558652  -0.43329182 ... -0.42602625 -0.39931747\n",
      "   3.552358  ]]\n",
      "MSE Train:  0.003536885\n",
      "MSE Test:  0.0037912587\n",
      "pred:  [[-0.50120234 -0.3525362  -0.43859178 ... -0.41941625 -0.38722438\n",
      "   3.816434  ]]\n",
      "MSE Train:  0.0038468933\n",
      "MSE Test:  0.0040312232\n",
      "pred:  [[-0.5103919  -0.3932687  -0.4572367  ... -0.43805307 -0.40872496\n",
      "   3.8250408 ]]\n",
      "MSE Train:  0.0043882327\n",
      "MSE Test:  0.004756451\n",
      "pred:  [[-0.5025093  -0.34646443 -0.43265918 ... -0.41418    -0.3888818\n",
      "   3.5369172 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.004016394\n",
      "MSE Test:  0.0043175076\n",
      "pred:  [[-0.50512046 -0.34928018 -0.41944963 ... -0.4059245  -0.373506\n",
      "   3.4684794 ]]\n",
      "MSE Train:  0.0043281303\n",
      "MSE Test:  0.00461128\n",
      "pred:  [[-0.49890727 -0.33624232 -0.41185826 ... -0.41837096 -0.3876065\n",
      "   3.6354206 ]]\n",
      "MSE Train:  0.0032221377\n",
      "MSE Test:  0.0035628823\n",
      "pred:  [[-0.506989   -0.37031665 -0.44080845 ... -0.4363766  -0.40152702\n",
      "   3.5325947 ]]\n",
      "MSE Train:  0.0029808278\n",
      "MSE Test:  0.0033104233\n",
      "pred:  [[-0.50618976 -0.36919397 -0.4421155  ... -0.44412327 -0.41321236\n",
      "   3.6459131 ]]\n",
      "MSE Train:  0.0031885053\n",
      "MSE Test:  0.0034707347\n",
      "pred:  [[-0.49844486 -0.36391655 -0.44042736 ... -0.44609252 -0.40832224\n",
      "   3.5896375 ]]\n",
      "MSE Train:  0.0032623284\n",
      "MSE Test:  0.003543399\n",
      "pred:  [[-0.5108715  -0.41284755 -0.45794487 ... -0.45192787 -0.42098257\n",
      "   3.6567569 ]]\n",
      "MSE Train:  0.0031717743\n",
      "MSE Test:  0.003399561\n",
      "pred:  [[-0.50658524 -0.3673403  -0.4317616  ... -0.44318995 -0.40607867\n",
      "   3.7468636 ]]\n",
      "MSE Train:  0.0037375551\n",
      "MSE Test:  0.004088312\n",
      "pred:  [[-0.5085042  -0.40807024 -0.4467197  ... -0.42739135 -0.3926502\n",
      "   3.4417272 ]]\n",
      "MSE Train:  0.0038306445\n",
      "MSE Test:  0.004073402\n",
      "pred:  [[-0.48736832 -0.34913796 -0.4077637  ... -0.40838957 -0.3415169\n",
      "   3.6433308 ]]\n",
      "MSE Train:  0.0032193996\n",
      "MSE Test:  0.0035433501\n",
      "pred:  [[-0.5181658  -0.38517657 -0.4489521  ... -0.45198855 -0.40565258\n",
      "   3.7591991 ]]\n",
      "MSE Train:  0.003673661\n",
      "MSE Test:  0.003954646\n",
      "pred:  [[-0.5331645  -0.39681292 -0.44866303 ... -0.43766502 -0.40462318\n",
      "   3.6147554 ]]\n",
      "MSE Train:  0.0029207605\n",
      "MSE Test:  0.0031890494\n",
      "pred:  [[-0.52019155 -0.38965893 -0.45882058 ... -0.4358141  -0.40466395\n",
      "   3.6613312 ]]\n",
      "MSE Train:  0.0027759804\n",
      "MSE Test:  0.003049332\n",
      "pred:  [[-0.5038036  -0.33627445 -0.43099532 ... -0.43129143 -0.38766447\n",
      "   3.7009459 ]]\n",
      "MSE Train:  0.0034669738\n",
      "MSE Test:  0.0036670363\n",
      "pred:  [[-0.511018   -0.38889486 -0.44677535 ... -0.44976258 -0.39273477\n",
      "   3.5483196 ]]\n",
      "MSE Train:  0.0028185276\n",
      "MSE Test:  0.0030766341\n",
      "pred:  [[-0.506476   -0.36854237 -0.4293636  ... -0.42100817 -0.39574307\n",
      "   3.8208885 ]]\n",
      "MSE Train:  0.003505549\n",
      "MSE Test:  0.0038197264\n",
      "pred:  [[-0.515394   -0.37813205 -0.44072634 ... -0.42912227 -0.3574593\n",
      "   3.5783856 ]]\n",
      "MSE Train:  0.002828231\n",
      "MSE Test:  0.0031151304\n",
      "pred:  [[-0.51407474 -0.36253786 -0.4302993  ... -0.42551538 -0.3832316\n",
      "   3.6699374 ]]\n",
      "MSE Train:  0.004022832\n",
      "MSE Test:  0.004234139\n",
      "pred:  [[-0.50798714 -0.3823265  -0.44218883 ... -0.45881984 -0.4302967\n",
      "   3.6699855 ]]\n",
      "MSE Train:  0.0030848898\n",
      "MSE Test:  0.003402696\n",
      "pred:  [[-0.5125329  -0.35958502 -0.43778124 ... -0.45168316 -0.386007\n",
      "   3.3203506 ]]\n",
      "MSE Train:  0.0027086106\n",
      "MSE Test:  0.0029743207\n",
      "pred:  [[-0.5215957  -0.38607755 -0.4514288  ... -0.44310668 -0.3588775\n",
      "   3.6184132 ]]\n",
      "MSE Train:  0.0027706537\n",
      "MSE Test:  0.0029405148\n",
      "pred:  [[-0.51400876 -0.3770935  -0.44505158 ... -0.45128542 -0.3852737\n",
      "   3.6967435 ]]\n",
      "MSE Train:  0.0033127023\n",
      "MSE Test:  0.0035648656\n",
      "pred:  [[-0.49706054 -0.34220448 -0.42995507 ... -0.41836104 -0.37208322\n",
      "   3.6685913 ]]\n",
      "MSE Train:  0.0029485368\n",
      "MSE Test:  0.003225732\n",
      "pred:  [[-0.49833512 -0.38388348 -0.4508675  ... -0.4472387  -0.39146382\n",
      "   3.4818447 ]]\n",
      "MSE Train:  0.0031190948\n",
      "MSE Test:  0.0033508376\n",
      "pred:  [[-0.51219386 -0.32837784 -0.42805517 ... -0.43125075 -0.38213578\n",
      "   3.6067739 ]]\n",
      "MSE Train:  0.003247933\n",
      "MSE Test:  0.003544709\n",
      "pred:  [[-0.5171968  -0.38723555 -0.45417738 ... -0.44888237 -0.40562293\n",
      "   3.6208973 ]]\n",
      "MSE Train:  0.0031303298\n",
      "MSE Test:  0.0032555507\n",
      "pred:  [[-0.5086248  -0.37043718 -0.44249764 ... -0.44896412 -0.38358626\n",
      "   3.8038635 ]]\n",
      "MSE Train:  0.0033041385\n",
      "MSE Test:  0.0035128307\n",
      "pred:  [[-0.4875855  -0.37250435 -0.4295491  ... -0.43714777 -0.3678744\n",
      "   3.7313879 ]]\n",
      "MSE Train:  0.002931336\n",
      "MSE Test:  0.0031562247\n",
      "pred:  [[-0.50767726 -0.3381904  -0.4286674  ... -0.42217273 -0.333741\n",
      "   3.5760944 ]]\n",
      "MSE Train:  0.0035235262\n",
      "MSE Test:  0.0037216041\n",
      "pred:  [[-0.52691054 -0.4435911  -0.4865046  ... -0.47296843 -0.399144\n",
      "   3.720664  ]]\n",
      "MSE Train:  0.0025540837\n",
      "MSE Test:  0.0028279468\n",
      "pred:  [[-0.50007796 -0.39600205 -0.45016742 ... -0.4444551  -0.36356878\n",
      "   3.6537964 ]]\n",
      "MSE Train:  0.002828997\n",
      "MSE Test:  0.0030715538\n",
      "pred:  [[-0.50748247 -0.34738353 -0.44426614 ... -0.42420313 -0.3665212\n",
      "   3.4235616 ]]\n",
      "MSE Train:  0.0030995414\n",
      "MSE Test:  0.0032259114\n",
      "pred:  [[-0.49666527 -0.4026504  -0.44916221 ... -0.43373534 -0.37429205\n",
      "   3.6171584 ]]\n",
      "MSE Train:  0.0026060762\n",
      "MSE Test:  0.0028902064\n",
      "pred:  [[-0.52221406 -0.38483825 -0.4504699  ... -0.44167405 -0.35657334\n",
      "   3.412157  ]]\n",
      "MSE Train:  0.0034849944\n",
      "MSE Test:  0.0036976638\n",
      "pred:  [[-0.49719554 -0.3458172  -0.44774562 ... -0.43034562 -0.3487375\n",
      "   3.4008362 ]]\n",
      "MSE Train:  0.0028540555\n",
      "MSE Test:  0.0031127122\n",
      "pred:  [[-0.5101741  -0.37394792 -0.4572059  ... -0.44847077 -0.37707037\n",
      "   3.466381  ]]\n",
      "MSE Train:  0.0028869307\n",
      "MSE Test:  0.0031242194\n",
      "pred:  [[-0.51087064 -0.36679357 -0.4528468  ... -0.44352904 -0.3913131\n",
      "   3.432357  ]]\n",
      "MSE Train:  0.0023020853\n",
      "MSE Test:  0.0025233529\n",
      "pred:  [[-0.5098671  -0.3696904  -0.45358127 ... -0.44919363 -0.36777434\n",
      "   3.6499949 ]]\n",
      "MSE Train:  0.0024409355\n",
      "MSE Test:  0.0026453445\n",
      "pred:  [[-0.5175764  -0.3752128  -0.46163753 ... -0.45225933 -0.38500655\n",
      "   3.6102939 ]]\n",
      "MSE Train:  0.0022657693\n",
      "MSE Test:  0.0024862718\n",
      "pred:  [[-0.5048206  -0.35905713 -0.4557042  ... -0.42543465 -0.3196712\n",
      "   3.581542  ]]\n",
      "MSE Train:  0.0032038284\n",
      "MSE Test:  0.0034014443\n",
      "pred:  [[-0.5232835  -0.42828783 -0.48185453 ... -0.4595017  -0.40424287\n",
      "   3.6749477 ]]\n",
      "MSE Train:  0.0023390495\n",
      "MSE Test:  0.0025076126\n",
      "pred:  [[-0.49512857 -0.3618111  -0.4355869  ... -0.42543948 -0.3636865\n",
      "   3.4483967 ]]\n",
      "MSE Train:  0.0025265901\n",
      "MSE Test:  0.002694176\n",
      "pred:  [[-0.5031803  -0.39287737 -0.46427777 ... -0.44469392 -0.35030884\n",
      "   3.7657318 ]]\n",
      "MSE Train:  0.002523682\n",
      "MSE Test:  0.0026999062\n",
      "pred:  [[-0.5067696  -0.4064256  -0.4612809  ... -0.4468286  -0.37358245\n",
      "   3.5962377 ]]\n",
      "MSE Train:  0.002313924\n",
      "MSE Test:  0.0024668628\n",
      "pred:  [[-0.50171715 -0.37193713 -0.44588432 ... -0.42841056 -0.35904512\n",
      "   3.790073  ]]\n",
      "MSE Train:  0.0022917928\n",
      "MSE Test:  0.0025123379\n",
      "pred:  [[-0.4920048  -0.39020336 -0.44825068 ... -0.44346514 -0.36914948\n",
      "   3.6563754 ]]\n",
      "MSE Train:  0.0023241807\n",
      "MSE Test:  0.0025489053\n",
      "pred:  [[-0.5016656  -0.35174936 -0.4375507  ... -0.42688558 -0.33493462\n",
      "   3.6199808 ]]\n",
      "MSE Train:  0.0031007596\n",
      "MSE Test:  0.003278945\n",
      "pred:  [[-0.5051466  -0.40566555 -0.45927966 ... -0.44455436 -0.36838907\n",
      "   4.070699  ]]\n",
      "MSE Train:  0.0021619422\n",
      "MSE Test:  0.002339279\n",
      "pred:  [[-0.50415313 -0.37675226 -0.4570683  ... -0.43838134 -0.36618954\n",
      "   3.5542424 ]]\n",
      "MSE Train:  0.0023989945\n",
      "MSE Test:  0.0025896744\n",
      "pred:  [[-0.5123248  -0.36230752 -0.45067498 ... -0.44060805 -0.3643452\n",
      "   3.7300491 ]]\n",
      "MSE Train:  0.002654501\n",
      "MSE Test:  0.0028711515\n",
      "pred:  [[-0.5110449  -0.40303725 -0.4648124  ... -0.44781208 -0.35259432\n",
      "   3.5186265 ]]\n",
      "MSE Train:  0.005534495\n",
      "MSE Test:  0.0058427076\n",
      "pred:  [[-0.4876898  -0.34958732 -0.4283387  ... -0.41475973 -0.33573514\n",
      "   3.5316632 ]]\n",
      "MSE Train:  0.0025172678\n",
      "MSE Test:  0.0027310562\n",
      "pred:  [[-0.49920768 -0.36521438 -0.4458413  ... -0.4410858  -0.3678165\n",
      "   3.6754704 ]]\n",
      "MSE Train:  0.0022738974\n",
      "MSE Test:  0.0024349631\n",
      "pred:  [[-0.5079132  -0.34588626 -0.44766375 ... -0.43209988 -0.33866695\n",
      "   3.533112  ]]\n",
      "MSE Train:  0.004317883\n",
      "MSE Test:  0.0044291182\n",
      "pred:  [[-0.50848156 -0.41330793 -0.46685827 ... -0.46129614 -0.38143417\n",
      "   3.7902782 ]]\n",
      "MSE Train:  0.0022122092\n",
      "MSE Test:  0.0023597113\n",
      "pred:  [[-0.49855363 -0.39949602 -0.45858127 ... -0.44617325 -0.35531503\n",
      "   3.6489835 ]]\n",
      "MSE Train:  0.0029956063\n",
      "MSE Test:  0.003217669\n",
      "pred:  [[-0.51389146 -0.423817   -0.48830572 ... -0.47859767 -0.39981833\n",
      "   3.556723  ]]\n",
      "MSE Train:  0.0019391568\n",
      "MSE Test:  0.0021349974\n",
      "pred:  [[-0.50004005 -0.3934703  -0.46647906 ... -0.42281836 -0.3550663\n",
      "   3.5224123 ]]\n",
      "MSE Train:  0.002323422\n",
      "MSE Test:  0.0024923312\n",
      "pred:  [[-0.507051   -0.3966277  -0.4644718  ... -0.433965   -0.35521072\n",
      "   3.7004964 ]]\n",
      "MSE Train:  0.0026226933\n",
      "MSE Test:  0.002744856\n",
      "pred:  [[-0.4899174  -0.3568539  -0.44186944 ... -0.41953307 -0.35002366\n",
      "   3.6392233 ]]\n",
      "MSE Train:  0.0021081031\n",
      "MSE Test:  0.0022789624\n",
      "pred:  [[-0.50804406 -0.36042744 -0.45522088 ... -0.43411905 -0.34702253\n",
      "   3.809099  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.004495551\n",
      "MSE Test:  0.004659163\n",
      "pred:  [[-0.508797   -0.4534476  -0.49123678 ... -0.46972275 -0.37078902\n",
      "   3.9208326 ]]\n",
      "MSE Train:  0.0019182346\n",
      "MSE Test:  0.0020789797\n",
      "pred:  [[-0.51196593 -0.38798967 -0.45484823 ... -0.4269402  -0.3519119\n",
      "   3.6473053 ]]\n",
      "MSE Train:  0.0021752438\n",
      "MSE Test:  0.0023285158\n",
      "pred:  [[-0.5076096  -0.37908953 -0.45684835 ... -0.45071924 -0.35766008\n",
      "   3.5930867 ]]\n",
      "MSE Train:  0.0020146298\n",
      "MSE Test:  0.0022001127\n",
      "pred:  [[-0.5067424  -0.35594004 -0.44495258 ... -0.4297139  -0.36397415\n",
      "   3.553907  ]]\n",
      "MSE Train:  0.002030102\n",
      "MSE Test:  0.002184189\n",
      "pred:  [[-0.5100542  -0.3824447  -0.45723525 ... -0.43268886 -0.35009196\n",
      "   3.6613352 ]]\n",
      "MSE Train:  0.0019830375\n",
      "MSE Test:  0.0021712594\n",
      "pred:  [[-0.5076211  -0.40280062 -0.4763488  ... -0.445477   -0.36416313\n",
      "   3.5071409 ]]\n",
      "MSE Train:  0.002138087\n",
      "MSE Test:  0.0023591623\n",
      "pred:  [[-0.51736647 -0.430032   -0.48127118 ... -0.46466202 -0.35762066\n",
      "   3.6569712 ]]\n",
      "MSE Train:  0.0021734105\n",
      "MSE Test:  0.002444693\n",
      "pred:  [[-0.5105254  -0.41345185 -0.4690706  ... -0.4537936  -0.36006436\n",
      "   3.7326112 ]]\n",
      "MSE Train:  0.0019192758\n",
      "MSE Test:  0.002142618\n",
      "pred:  [[-0.5044347  -0.39175725 -0.45886928 ... -0.43622863 -0.3474643\n",
      "   3.7276716 ]]\n",
      "MSE Train:  0.0018539341\n",
      "MSE Test:  0.002064461\n",
      "pred:  [[-0.51177    -0.39159298 -0.45967227 ... -0.44123864 -0.36837143\n",
      "   3.5434918 ]]\n",
      "MSE Train:  0.0022456618\n",
      "MSE Test:  0.0024144112\n",
      "pred:  [[-0.5097361  -0.40524328 -0.4675874  ... -0.439313   -0.36590937\n",
      "   3.7300007 ]]\n",
      "MSE Train:  0.0028395026\n",
      "MSE Test:  0.0029513587\n",
      "pred:  [[-0.4794048  -0.33251968 -0.41975114 ... -0.4077721  -0.28696567\n",
      "   3.6274421 ]]\n",
      "MSE Train:  0.0019697174\n",
      "MSE Test:  0.0021525433\n",
      "pred:  [[-0.5055658  -0.37416315 -0.46588144 ... -0.43325427 -0.33121213\n",
      "   3.609016  ]]\n",
      "MSE Train:  0.002326759\n",
      "MSE Test:  0.0024741532\n",
      "pred:  [[-0.50091213 -0.4003921  -0.46618953 ... -0.44154292 -0.34177932\n",
      "   3.648095  ]]\n",
      "MSE Train:  0.0019668976\n",
      "MSE Test:  0.002130233\n",
      "pred:  [[-0.5034549  -0.39127988 -0.45641726 ... -0.43696243 -0.3545701\n",
      "   3.7610753 ]]\n",
      "MSE Train:  0.0021197675\n",
      "MSE Test:  0.0022509738\n",
      "pred:  [[-0.48693866 -0.37649855 -0.45502228 ... -0.4296589  -0.33358037\n",
      "   3.639981  ]]\n",
      "MSE Train:  0.0020480123\n",
      "MSE Test:  0.0022206793\n",
      "pred:  [[-0.49806368 -0.3614929  -0.44499385 ... -0.4241068  -0.3567123\n",
      "   3.6578405 ]]\n",
      "MSE Train:  0.0028595275\n",
      "MSE Test:  0.0029626316\n",
      "pred:  [[-0.4863264  -0.36870122 -0.4571405  ... -0.4229495  -0.334337\n",
      "   3.5975187 ]]\n",
      "MSE Train:  0.0018298506\n",
      "MSE Test:  0.001962416\n",
      "pred:  [[-0.50847846 -0.39689553 -0.4741131  ... -0.43078533 -0.33719534\n",
      "   3.614882  ]]\n",
      "MSE Train:  0.0015940802\n",
      "MSE Test:  0.0017468563\n",
      "pred:  [[-0.5127276  -0.39658365 -0.47248238 ... -0.43932536 -0.36001557\n",
      "   3.6613822 ]]\n",
      "MSE Train:  0.0015511217\n",
      "MSE Test:  0.0016926832\n",
      "pred:  [[-0.50140256 -0.39299852 -0.4621285  ... -0.40126976 -0.3384112\n",
      "   3.5606368 ]]\n",
      "MSE Train:  0.0021974156\n",
      "MSE Test:  0.002364751\n",
      "pred:  [[-0.52077305 -0.41203478 -0.46797773 ... -0.44860312 -0.3738967\n",
      "   3.5124905 ]]\n",
      "MSE Train:  0.0018263195\n",
      "MSE Test:  0.0020307526\n",
      "pred:  [[-0.52103555 -0.4145491  -0.48407    ... -0.44150424 -0.36489427\n",
      "   3.588141  ]]\n",
      "MSE Train:  0.0018079525\n",
      "MSE Test:  0.002013869\n",
      "pred:  [[-0.5072662  -0.38673958 -0.456626   ... -0.4230986  -0.3332324\n",
      "   3.5474398 ]]\n",
      "MSE Train:  0.0016118072\n",
      "MSE Test:  0.0017351981\n",
      "pred:  [[-0.51018536 -0.37963217 -0.45754248 ... -0.42739335 -0.34397924\n",
      "   3.53696   ]]\n",
      "MSE Train:  0.002025839\n",
      "MSE Test:  0.002237008\n",
      "pred:  [[-0.5089614  -0.3862051  -0.46329716 ... -0.42647764 -0.34427768\n",
      "   3.546846  ]]\n",
      "MSE Train:  0.0015886017\n",
      "MSE Test:  0.0017447929\n",
      "pred:  [[-0.5064082  -0.4094406  -0.4780426  ... -0.4423941  -0.31907326\n",
      "   3.5770087 ]]\n",
      "MSE Train:  0.001624384\n",
      "MSE Test:  0.0017739264\n",
      "pred:  [[-0.5031481  -0.38212818 -0.45952582 ... -0.42434922 -0.3601028\n",
      "   3.5707023 ]]\n",
      "MSE Train:  0.0016078833\n",
      "MSE Test:  0.0017427591\n",
      "pred:  [[-0.5000241  -0.39450684 -0.4669241  ... -0.44835505 -0.36539313\n",
      "   3.6264446 ]]\n",
      "MSE Train:  0.0017786982\n",
      "MSE Test:  0.0018654474\n",
      "pred:  [[-0.5036845  -0.39520213 -0.47098067 ... -0.43356386 -0.35173184\n",
      "   3.6705737 ]]\n",
      "MSE Train:  0.0015649252\n",
      "MSE Test:  0.0017128051\n",
      "pred:  [[-0.5063746  -0.39455295 -0.47157916 ... -0.4279585  -0.34240782\n",
      "   3.543396  ]]\n",
      "MSE Train:  0.001794672\n",
      "MSE Test:  0.0019068819\n",
      "pred:  [[-0.5005682  -0.39455158 -0.46337095 ... -0.41315556 -0.3450524\n",
      "   3.4563231 ]]\n",
      "MSE Train:  0.0017421625\n",
      "MSE Test:  0.0019169766\n",
      "pred:  [[-0.5027696  -0.40115917 -0.46397057 ... -0.42156145 -0.32095358\n",
      "   3.5924263 ]]\n",
      "MSE Train:  0.002166968\n",
      "MSE Test:  0.002299664\n",
      "pred:  [[-0.4925825  -0.36329377 -0.44493842 ... -0.42383215 -0.3210632\n",
      "   3.5402784 ]]\n",
      "MSE Train:  0.0016342911\n",
      "MSE Test:  0.0017780857\n",
      "pred:  [[-0.50713307 -0.41957814 -0.48264837 ... -0.44473225 -0.3806432\n",
      "   3.6126769 ]]\n",
      "MSE Train:  0.0021374696\n",
      "MSE Test:  0.0022950931\n",
      "pred:  [[-0.5003842  -0.42450428 -0.47610837 ... -0.43218943 -0.35223612\n",
      "   3.754328  ]]\n",
      "MSE Train:  0.0016077708\n",
      "MSE Test:  0.0017624467\n",
      "pred:  [[-0.49794728 -0.40152207 -0.461861   ... -0.43429953 -0.36080647\n",
      "   3.689181  ]]\n",
      "MSE Train:  0.0021498776\n",
      "MSE Test:  0.0022991358\n",
      "pred:  [[-0.4914117  -0.37386298 -0.44408166 ... -0.40170515 -0.32097936\n",
      "   3.7491798 ]]\n",
      "MSE Train:  0.0016827981\n",
      "MSE Test:  0.0018084225\n",
      "pred:  [[-0.4943276  -0.39322266 -0.4460705  ... -0.42963338 -0.35391074\n",
      "   3.6883347 ]]\n",
      "MSE Train:  0.0014655422\n",
      "MSE Test:  0.0016091432\n",
      "pred:  [[-0.49811605 -0.39118302 -0.44903326 ... -0.42898837 -0.3570504\n",
      "   3.5245712 ]]\n",
      "MSE Train:  0.0019626021\n",
      "MSE Test:  0.0020349112\n",
      "pred:  [[-0.5055903  -0.41450882 -0.4659658  ... -0.41991287 -0.34421712\n",
      "   3.754055  ]]\n",
      "MSE Train:  0.001886872\n",
      "MSE Test:  0.002043389\n",
      "pred:  [[-0.5024947 -0.3833869 -0.461648  ... -0.4333122 -0.3528912  3.5089915]]\n",
      "MSE Train:  0.0040730312\n",
      "MSE Test:  0.004247223\n",
      "pred:  [[-0.51930004 -0.40762252 -0.4700588  ... -0.4325141  -0.36217788\n",
      "   3.3747103 ]]\n",
      "MSE Train:  0.0025858728\n",
      "MSE Test:  0.002648916\n",
      "pred:  [[-0.491852   -0.3287044  -0.4365098  ... -0.3969166  -0.34615055\n",
      "   3.7638872 ]]\n",
      "MSE Train:  0.0017795557\n",
      "MSE Test:  0.001896527\n",
      "pred:  [[-0.5157928  -0.38194507 -0.47646168 ... -0.4220394  -0.3475448\n",
      "   3.8154516 ]]\n",
      "MSE Train:  0.0022223077\n",
      "MSE Test:  0.0023268028\n",
      "pred:  [[-0.5268212  -0.3997025  -0.4740473  ... -0.4327994  -0.37433323\n",
      "   3.6659238 ]]\n",
      "MSE Train:  0.0018146591\n",
      "MSE Test:  0.001978557\n",
      "pred:  [[-0.5185722  -0.40759155 -0.46920475 ... -0.44652224 -0.36309856\n",
      "   3.5397027 ]]\n",
      "MSE Train:  0.0018287153\n",
      "MSE Test:  0.0019513754\n",
      "pred:  [[-0.49653953 -0.35872224 -0.45026767 ... -0.40990347 -0.30906326\n",
      "   3.529225  ]]\n",
      "MSE Train:  0.0015567435\n",
      "MSE Test:  0.0017170262\n",
      "pred:  [[-0.50889033 -0.3775752  -0.4600876  ... -0.42794576 -0.3510785\n",
      "   3.6972275 ]]\n",
      "MSE Train:  0.0022503645\n",
      "MSE Test:  0.0023568727\n",
      "pred:  [[-0.5124959  -0.39828074 -0.4694172  ... -0.4584551  -0.3717147\n",
      "   3.6548204 ]]\n",
      "MSE Train:  0.00234206\n",
      "MSE Test:  0.0024751595\n",
      "pred:  [[-0.4856398  -0.3517996  -0.43178892 ... -0.41449296 -0.3277014\n",
      "   3.542342  ]]\n",
      "MSE Train:  0.0014642731\n",
      "MSE Test:  0.0015964272\n",
      "pred:  [[-0.51317644 -0.3615139  -0.45970988 ... -0.4235679  -0.3296644\n",
      "   3.7804792 ]]\n",
      "MSE Train:  0.0014435292\n",
      "MSE Test:  0.0015442098\n",
      "pred:  [[-0.5098518  -0.39351118 -0.46737295 ... -0.4368365  -0.35566235\n",
      "   3.7252157 ]]\n",
      "MSE Train:  0.0013647752\n",
      "MSE Test:  0.0014991135\n",
      "pred:  [[-0.50401366 -0.3724092  -0.44591358 ... -0.40678167 -0.30398828\n",
      "   3.5934863 ]]\n",
      "MSE Train:  0.0017025972\n",
      "MSE Test:  0.0018497558\n",
      "pred:  [[-0.5136633  -0.3819998  -0.45290032 ... -0.42917848 -0.3600855\n",
      "   3.6643355 ]]\n",
      "MSE Train:  0.001476412\n",
      "MSE Test:  0.0015781343\n",
      "pred:  [[-0.50702155 -0.37766162 -0.44705606 ... -0.417336   -0.32248062\n",
      "   3.69887   ]]\n",
      "MSE Train:  0.0014602732\n",
      "MSE Test:  0.0016085816\n",
      "pred:  [[-0.51090467 -0.39756247 -0.46854055 ... -0.44219235 -0.36495593\n",
      "   3.7229128 ]]\n",
      "MSE Train:  0.0018679481\n",
      "MSE Test:  0.0020236836\n",
      "pred:  [[-0.5241904  -0.42213172 -0.48265642 ... -0.44945127 -0.38016716\n",
      "   3.3500135 ]]\n",
      "MSE Train:  0.0020542461\n",
      "MSE Test:  0.0022839021\n",
      "pred:  [[-0.5161263  -0.39350063 -0.4635238  ... -0.4349271  -0.35286862\n",
      "   3.615269  ]]\n",
      "MSE Train:  0.001612756\n",
      "MSE Test:  0.0017245644\n",
      "pred:  [[-0.5003016  -0.37901875 -0.45257622 ... -0.41770157 -0.31481287\n",
      "   3.723491  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.0015106882\n",
      "MSE Test:  0.0016967119\n",
      "pred:  [[-0.524945   -0.38962042 -0.4714815  ... -0.42692792 -0.35734686\n",
      "   3.6119697 ]]\n",
      "MSE Train:  0.0017930317\n",
      "MSE Test:  0.0018639024\n",
      "pred:  [[-0.5114418  -0.3826206  -0.4465006  ... -0.4120256  -0.33013043\n",
      "   3.683849  ]]\n",
      "MSE Train:  0.001399183\n",
      "MSE Test:  0.001529925\n",
      "pred:  [[-0.50343615 -0.38109836 -0.45240447 ... -0.43530715 -0.35931212\n",
      "   3.5936298 ]]\n",
      "MSE Train:  0.001530514\n",
      "MSE Test:  0.0016469589\n",
      "pred:  [[-0.5051583  -0.37770092 -0.4601644  ... -0.42164025 -0.33098158\n",
      "   3.606781  ]]\n",
      "MSE Train:  0.0014391432\n",
      "MSE Test:  0.0016014372\n",
      "pred:  [[-0.51008093 -0.41053367 -0.4699121  ... -0.46039322 -0.3700217\n",
      "   3.6062167 ]]\n",
      "MSE Train:  0.0012669321\n",
      "MSE Test:  0.0013704695\n",
      "pred:  [[-0.505685   -0.3807918  -0.45785594 ... -0.44208074 -0.36424956\n",
      "   3.5792828 ]]\n",
      "MSE Train:  0.0017747696\n",
      "MSE Test:  0.0018998341\n",
      "pred:  [[-0.51317173 -0.40898386 -0.45920616 ... -0.44414976 -0.33120695\n",
      "   3.576294  ]]\n",
      "MSE Train:  0.0015921638\n",
      "MSE Test:  0.0017269606\n",
      "pred:  [[-0.51716256 -0.3920547  -0.45702323 ... -0.45566848 -0.37492573\n",
      "   3.6101656 ]]\n",
      "MSE Train:  0.0017704077\n",
      "MSE Test:  0.0018404834\n",
      "pred:  [[-0.5159118  -0.3820886  -0.46623436 ... -0.42576638 -0.29951456\n",
      "   3.6174774 ]]\n",
      "MSE Train:  0.0012645957\n",
      "MSE Test:  0.0014621695\n",
      "pred:  [[-0.5152863  -0.376113   -0.46360147 ... -0.4423548  -0.33169574\n",
      "   3.549411  ]]\n",
      "MSE Train:  0.0019273686\n",
      "MSE Test:  0.0020479066\n",
      "pred:  [[-0.52474445 -0.41115355 -0.4672563  ... -0.46626133 -0.35681802\n",
      "   3.5945451 ]]\n",
      "MSE Train:  0.0017980754\n",
      "MSE Test:  0.0018465724\n",
      "pred:  [[-0.5274271  -0.38748538 -0.4599973  ... -0.45113176 -0.3165723\n",
      "   3.719759  ]]\n",
      "MSE Train:  0.0016355834\n",
      "MSE Test:  0.0017739445\n",
      "pred:  [[-0.5150852  -0.4086465  -0.46384722 ... -0.44718704 -0.34355563\n",
      "   3.5329406 ]]\n",
      "MSE Train:  0.0020194745\n",
      "MSE Test:  0.002129741\n",
      "pred:  [[-0.50317615 -0.3729022  -0.44354567 ... -0.4130968  -0.3038954\n",
      "   3.5329974 ]]\n",
      "MSE Train:  0.0014389139\n",
      "MSE Test:  0.0015326234\n",
      "pred:  [[-0.5130625  -0.38153154 -0.4672264  ... -0.4510532  -0.31849605\n",
      "   3.7400692 ]]\n",
      "MSE Train:  0.001380655\n",
      "MSE Test:  0.0015230874\n",
      "pred:  [[-0.49942532 -0.38517958 -0.45351517 ... -0.42080456 -0.29349938\n",
      "   3.5969646 ]]\n",
      "MSE Train:  0.0023819015\n",
      "MSE Test:  0.0025866972\n",
      "pred:  [[-0.5184209  -0.41703853 -0.47323707 ... -0.4579812  -0.35333964\n",
      "   3.5312195 ]]\n",
      "MSE Train:  0.0016209757\n",
      "MSE Test:  0.0017530896\n",
      "pred:  [[-0.5236726  -0.40715966 -0.47048962 ... -0.45567426 -0.343569\n",
      "   3.4877746 ]]\n",
      "MSE Train:  0.0015564354\n",
      "MSE Test:  0.0016944144\n",
      "pred:  [[-0.50940526 -0.36280048 -0.44533008 ... -0.44086882 -0.3167474\n",
      "   3.7739341 ]]\n",
      "MSE Train:  0.0016433763\n",
      "MSE Test:  0.001786805\n",
      "pred:  [[-0.5346093  -0.4092936  -0.47802103 ... -0.44999057 -0.3469002\n",
      "   3.504848  ]]\n",
      "MSE Train:  0.00146106\n",
      "MSE Test:  0.0015252088\n",
      "pred:  [[-0.51251084 -0.38537621 -0.45997044 ... -0.42498374 -0.34981322\n",
      "   3.639351  ]]\n",
      "MSE Train:  0.001215938\n",
      "MSE Test:  0.0013138088\n",
      "pred:  [[-0.50461423 -0.3631342  -0.44918078 ... -0.42918494 -0.29481554\n",
      "   3.7135272 ]]\n",
      "MSE Train:  0.0013389515\n",
      "MSE Test:  0.0014165986\n",
      "pred:  [[-0.51409113 -0.40001333 -0.4648934  ... -0.4402488  -0.3431744\n",
      "   3.6789086 ]]\n",
      "MSE Train:  0.0012704905\n",
      "MSE Test:  0.0013637375\n",
      "pred:  [[-0.5103919  -0.38453737 -0.45620167 ... -0.42949098 -0.34097955\n",
      "   3.4349031 ]]\n",
      "MSE Train:  0.0015786809\n",
      "MSE Test:  0.0016237365\n",
      "pred:  [[-0.52377707 -0.4073806  -0.4618737  ... -0.44275475 -0.358937\n",
      "   3.7197325 ]]\n",
      "MSE Train:  0.0013119251\n",
      "MSE Test:  0.0014427908\n",
      "pred:  [[-0.529647   -0.417351   -0.47185487 ... -0.44387567 -0.3455804\n",
      "   3.6155717 ]]\n",
      "MSE Train:  0.001453312\n",
      "MSE Test:  0.0015640034\n",
      "pred:  [[-0.5125232  -0.37310973 -0.4541333  ... -0.4230856  -0.32240745\n",
      "   3.6296465 ]]\n",
      "MSE Train:  0.0015335011\n",
      "MSE Test:  0.001628908\n",
      "pred:  [[-0.5184463  -0.40593335 -0.46643326 ... -0.4319392  -0.3293651\n",
      "   3.6979036 ]]\n",
      "MSE Train:  0.0015534009\n",
      "MSE Test:  0.0016983203\n",
      "pred:  [[-0.5254319  -0.3901869  -0.46446288 ... -0.4450004  -0.36076343\n",
      "   3.360038  ]]\n",
      "MSE Train:  0.0012644373\n",
      "MSE Test:  0.0013616062\n",
      "pred:  [[-0.50957876 -0.37101945 -0.45721892 ... -0.44541755 -0.33717576\n",
      "   3.8560638 ]]\n",
      "MSE Train:  0.0013106379\n",
      "MSE Test:  0.0014015059\n",
      "pred:  [[-0.49970737 -0.38715252 -0.4486846  ... -0.42233744 -0.33306\n",
      "   3.5279403 ]]\n",
      "MSE Train:  0.0011040979\n",
      "MSE Test:  0.0011965028\n",
      "pred:  [[-0.5133319  -0.38489997 -0.45601845 ... -0.44344836 -0.35452676\n",
      "   3.67082   ]]\n",
      "MSE Train:  0.0013183671\n",
      "MSE Test:  0.0014497306\n",
      "pred:  [[-0.5100389  -0.36881217 -0.44582006 ... -0.42949003 -0.32475868\n",
      "   3.7219439 ]]\n",
      "MSE Train:  0.003399897\n",
      "MSE Test:  0.003527236\n",
      "pred:  [[-0.5378999  -0.40000945 -0.46747202 ... -0.45989364 -0.36806118\n",
      "   3.546272  ]]\n",
      "MSE Train:  0.0024368868\n",
      "MSE Test:  0.0025088838\n",
      "pred:  [[-0.49934003 -0.36172953 -0.43919027 ... -0.42592344 -0.306742\n",
      "   3.5208862 ]]\n",
      "MSE Train:  0.0013845578\n",
      "MSE Test:  0.0015202363\n",
      "pred:  [[-0.5181036  -0.393601   -0.46085176 ... -0.44111556 -0.3534394\n",
      "   3.7108755 ]]\n",
      "MSE Train:  0.0012351142\n",
      "MSE Test:  0.0013303895\n",
      "pred:  [[-0.52540725 -0.41292882 -0.4633608  ... -0.44187915 -0.34285152\n",
      "   3.5902765 ]]\n",
      "MSE Train:  0.0017272432\n",
      "MSE Test:  0.001799461\n",
      "pred:  [[-0.5069856  -0.36572218 -0.44084683 ... -0.41692942 -0.32281384\n",
      "   3.7616024 ]]\n",
      "MSE Train:  0.001059097\n",
      "MSE Test:  0.0011763156\n",
      "pred:  [[-0.5231782  -0.39788067 -0.45608228 ... -0.4417731  -0.32298476\n",
      "   3.6307373 ]]\n",
      "MSE Train:  0.0011686566\n",
      "MSE Test:  0.001286469\n",
      "pred:  [[-0.515679   -0.38135076 -0.44753426 ... -0.41883808 -0.32598293\n",
      "   3.6570551 ]]\n",
      "MSE Train:  0.0013928786\n",
      "MSE Test:  0.0015140616\n",
      "pred:  [[-0.5242629  -0.3963552  -0.45390525 ... -0.43811598 -0.32698444\n",
      "   3.5444002 ]]\n",
      "MSE Train:  0.0012583497\n",
      "MSE Test:  0.0013911058\n",
      "pred:  [[-0.52413887 -0.40886396 -0.47270796 ... -0.4398102  -0.36636677\n",
      "   3.5349479 ]]\n",
      "MSE Train:  0.0017889087\n",
      "MSE Test:  0.0018733141\n",
      "pred:  [[-0.49545103 -0.3505899  -0.43149945 ... -0.4067943  -0.29729408\n",
      "   3.6468742 ]]\n",
      "MSE Train:  0.0014819903\n",
      "MSE Test:  0.0015681341\n",
      "pred:  [[-0.5235006  -0.401446   -0.4705126  ... -0.4359891  -0.31901023\n",
      "   3.721674  ]]\n",
      "MSE Train:  0.0017989399\n",
      "MSE Test:  0.001965293\n",
      "pred:  [[-0.53420967 -0.42550138 -0.4749377  ... -0.45329604 -0.37741032\n",
      "   3.6799235 ]]\n",
      "MSE Train:  0.0027536734\n",
      "MSE Test:  0.002856529\n",
      "pred:  [[-0.52273715 -0.43514395 -0.46637717 ... -0.44594508 -0.3830347\n",
      "   3.7270079 ]]\n",
      "MSE Train:  0.0015126579\n",
      "MSE Test:  0.0016412255\n",
      "pred:  [[-0.52191174 -0.391935   -0.45165998 ... -0.4322666  -0.3453759\n",
      "   3.5861776 ]]\n",
      "MSE Train:  0.001101109\n",
      "MSE Test:  0.0012486377\n",
      "pred:  [[-0.5278628  -0.39471644 -0.4508909  ... -0.42287123 -0.32575035\n",
      "   3.727769  ]]\n",
      "MSE Train:  0.0010942767\n",
      "MSE Test:  0.0012022477\n",
      "pred:  [[-0.5201609  -0.4107562  -0.45554072 ... -0.4255754  -0.32036036\n",
      "   3.7751803 ]]\n",
      "MSE Train:  0.001372608\n",
      "MSE Test:  0.0014839486\n",
      "pred:  [[-0.52133036 -0.39483497 -0.4542271  ... -0.42242312 -0.32595417\n",
      "   3.7155879 ]]\n",
      "MSE Train:  0.0013274628\n",
      "MSE Test:  0.0014004916\n",
      "pred:  [[-0.50503886 -0.37683153 -0.44423163 ... -0.4159937  -0.3311731\n",
      "   3.6405628 ]]\n",
      "MSE Train:  0.001518997\n",
      "MSE Test:  0.0016588044\n",
      "pred:  [[-0.53058827 -0.42618698 -0.4717523  ... -0.44294912 -0.35519376\n",
      "   3.5694416 ]]\n",
      "MSE Train:  0.0010054195\n",
      "MSE Test:  0.001120944\n",
      "pred:  [[-0.51220524 -0.40375075 -0.45843896 ... -0.4320161  -0.34170583\n",
      "   3.7284422 ]]\n",
      "MSE Train:  0.0011515683\n",
      "MSE Test:  0.0012647848\n",
      "pred:  [[-0.5172428  -0.39058322 -0.4578508  ... -0.41940194 -0.34070283\n",
      "   3.6793528 ]]\n",
      "MSE Train:  0.0011665425\n",
      "MSE Test:  0.0012624668\n",
      "pred:  [[-0.5236199  -0.40732366 -0.46956706 ... -0.44238657 -0.36832172\n",
      "   3.6786659 ]]\n",
      "MSE Train:  0.0017559772\n",
      "MSE Test:  0.0018228325\n",
      "pred:  [[-0.5269343  -0.41985065 -0.46671724 ... -0.45130146 -0.37230998\n",
      "   3.8162777 ]]\n",
      "MSE Train:  0.001178243\n",
      "MSE Test:  0.0012547346\n",
      "pred:  [[-0.5255192  -0.41675794 -0.4669909  ... -0.44879317 -0.36314464\n",
      "   3.6109962 ]]\n",
      "MSE Train:  0.0012220778\n",
      "MSE Test:  0.0013216317\n",
      "pred:  [[-0.51624846 -0.38110256 -0.45462152 ... -0.43221873 -0.33269575\n",
      "   3.5724044 ]]\n",
      "MSE Train:  0.0012776362\n",
      "MSE Test:  0.0013740328\n",
      "pred:  [[-0.51737463 -0.38346884 -0.4533436  ... -0.4335883  -0.35252094\n",
      "   3.7234108 ]]\n",
      "MSE Train:  0.0013067726\n",
      "MSE Test:  0.0013995834\n",
      "pred:  [[-0.51852226 -0.39355928 -0.45731    ... -0.44112557 -0.35916924\n",
      "   3.6099517 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.0014097557\n",
      "MSE Test:  0.0015429249\n",
      "pred:  [[-0.50860465 -0.39110926 -0.44897008 ... -0.43243492 -0.32308793\n",
      "   3.6417367 ]]\n",
      "MSE Train:  0.0018152748\n",
      "MSE Test:  0.0019069646\n",
      "pred:  [[-0.5019549  -0.3484517  -0.42779368 ... -0.42232436 -0.3158571\n",
      "   3.809165  ]]\n",
      "MSE Train:  0.0010689505\n",
      "MSE Test:  0.0011454996\n",
      "pred:  [[-0.5198527  -0.40704933 -0.45842242 ... -0.44257826 -0.3596217\n",
      "   3.6544132 ]]\n",
      "MSE Train:  0.0010339202\n",
      "MSE Test:  0.0011645498\n",
      "pred:  [[-0.5199755  -0.41038913 -0.4657791  ... -0.4462287  -0.32471392\n",
      "   3.6344721 ]]\n",
      "MSE Train:  0.0010562919\n",
      "MSE Test:  0.0011596751\n",
      "pred:  [[-0.5211413  -0.42181677 -0.46643236 ... -0.44423312 -0.325022\n",
      "   3.6863    ]]\n",
      "MSE Train:  0.0015024173\n",
      "MSE Test:  0.0015835966\n",
      "pred:  [[-0.5075569  -0.4143239  -0.45051363 ... -0.42926013 -0.33551273\n",
      "   3.6745512 ]]\n",
      "MSE Train:  0.0017825663\n",
      "MSE Test:  0.0018745018\n",
      "pred:  [[-0.5158294  -0.38664144 -0.45299634 ... -0.43733266 -0.31142253\n",
      "   3.7148852 ]]\n",
      "MSE Train:  0.0010766936\n",
      "MSE Test:  0.0011405338\n",
      "pred:  [[-0.5281691  -0.40883416 -0.45676118 ... -0.43654576 -0.3709104\n",
      "   3.6977274 ]]\n",
      "MSE Train:  0.0011097603\n",
      "MSE Test:  0.0012418928\n",
      "pred:  [[-0.52450836 -0.41103727 -0.4631876  ... -0.4328463  -0.32736498\n",
      "   3.6569753 ]]\n",
      "MSE Train:  0.0012233834\n",
      "MSE Test:  0.0013326653\n",
      "pred:  [[-0.51463807 -0.41769856 -0.4580509  ... -0.44078153 -0.35120165\n",
      "   3.5399594 ]]\n",
      "MSE Train:  0.001166954\n",
      "MSE Test:  0.0012731613\n",
      "pred:  [[-0.5137007  -0.40403053 -0.4593126  ... -0.43815875 -0.34299913\n",
      "   3.8170545 ]]\n",
      "MSE Train:  0.0015869988\n",
      "MSE Test:  0.0016592422\n",
      "pred:  [[-0.5024954  -0.3698429  -0.4403207  ... -0.40892056 -0.30280894\n",
      "   3.7714033 ]]\n",
      "MSE Train:  0.0012472589\n",
      "MSE Test:  0.0013680672\n",
      "pred:  [[-0.51492614 -0.38918304 -0.45419902 ... -0.423944   -0.3524673\n",
      "   3.728605  ]]\n",
      "MSE Train:  0.0016991228\n",
      "MSE Test:  0.0017608315\n",
      "pred:  [[-0.5239931  -0.39104176 -0.45909914 ... -0.4338339  -0.32747155\n",
      "   3.6916857 ]]\n",
      "MSE Train:  0.0012070859\n",
      "MSE Test:  0.0012972921\n",
      "pred:  [[-0.5312582  -0.40618926 -0.46742138 ... -0.4368513  -0.32159734\n",
      "   3.6361187 ]]\n",
      "MSE Train:  0.0010103919\n",
      "MSE Test:  0.0011219223\n",
      "pred:  [[-0.5136579  -0.39859217 -0.4547266  ... -0.43193495 -0.3239361\n",
      "   3.6367917 ]]\n",
      "MSE Train:  0.00113272\n",
      "MSE Test:  0.0012573571\n",
      "pred:  [[-0.5224889  -0.3922343  -0.44847885 ... -0.44147605 -0.32485244\n",
      "   3.5772297 ]]\n",
      "MSE Train:  0.00107953\n",
      "MSE Test:  0.0011757013\n",
      "pred:  [[-0.52306825 -0.40570754 -0.4620145  ... -0.43478656 -0.348045\n",
      "   3.602837  ]]\n",
      "MSE Train:  0.0009926585\n",
      "MSE Test:  0.0010841162\n",
      "pred:  [[-0.5168037  -0.39880946 -0.45097435 ... -0.4392322  -0.35899073\n",
      "   3.6552582 ]]\n",
      "MSE Train:  0.0009918232\n",
      "MSE Test:  0.0010736907\n",
      "pred:  [[-0.5150468  -0.3774831  -0.452455   ... -0.4281931  -0.29385012\n",
      "   3.7247941 ]]\n",
      "MSE Train:  0.0014351003\n",
      "MSE Test:  0.0015221521\n",
      "pred:  [[-0.5132859  -0.35213596 -0.44238007 ... -0.418167   -0.2796312\n",
      "   3.6429296 ]]\n",
      "MSE Train:  0.00090764527\n",
      "MSE Test:  0.0010075497\n",
      "pred:  [[-0.5113678  -0.38998523 -0.4522428  ... -0.43197486 -0.340474\n",
      "   3.6075878 ]]\n",
      "MSE Train:  0.0011007515\n",
      "MSE Test:  0.0012028672\n",
      "pred:  [[-0.51949406 -0.39647296 -0.4586387  ... -0.4495114  -0.3199828\n",
      "   3.6493044 ]]\n",
      "MSE Train:  0.0010358333\n",
      "MSE Test:  0.0011152675\n",
      "pred:  [[-0.5169164  -0.3914588  -0.45999646 ... -0.43484065 -0.3363761\n",
      "   3.7316976 ]]\n",
      "MSE Train:  0.0012464882\n",
      "MSE Test:  0.0013395203\n",
      "pred:  [[-0.51536894 -0.39499348 -0.4631621  ... -0.43053415 -0.2986002\n",
      "   3.7097394 ]]\n",
      "MSE Train:  0.0012306144\n",
      "MSE Test:  0.0013229962\n",
      "pred:  [[-0.49901962 -0.37504652 -0.43962255 ... -0.42353618 -0.31764728\n",
      "   3.6063848 ]]\n",
      "MSE Train:  0.0011879024\n",
      "MSE Test:  0.0013182504\n",
      "pred:  [[-0.5186704  -0.40330154 -0.45996922 ... -0.45212322 -0.34393257\n",
      "   3.6187596 ]]\n",
      "MSE Train:  0.0013581854\n",
      "MSE Test:  0.0014421305\n",
      "pred:  [[-0.5297098  -0.39073715 -0.46218753 ... -0.44690868 -0.3539955\n",
      "   3.6375804 ]]\n",
      "MSE Train:  0.0013427995\n",
      "MSE Test:  0.0014175173\n",
      "pred:  [[-0.50346303 -0.3810904  -0.4441743  ... -0.43216956 -0.31513515\n",
      "   3.5961585 ]]\n",
      "MSE Train:  0.0014201101\n",
      "MSE Test:  0.0015407157\n",
      "pred:  [[-0.5142857  -0.38196638 -0.44651067 ... -0.42918453 -0.31140918\n",
      "   3.8800914 ]]\n",
      "MSE Train:  0.0010789501\n",
      "MSE Test:  0.0012031832\n",
      "pred:  [[-0.5130258  -0.39207596 -0.45216578 ... -0.43899095 -0.30865043\n",
      "   3.5579088 ]]\n",
      "MSE Train:  0.0010437669\n",
      "MSE Test:  0.0011625083\n",
      "pred:  [[-0.5145441  -0.3996445  -0.46021706 ... -0.44362524 -0.32400298\n",
      "   3.6261582 ]]\n",
      "MSE Train:  0.00089847407\n",
      "MSE Test:  0.000978035\n",
      "pred:  [[-0.5151745  -0.4024624  -0.4531758  ... -0.4430648  -0.30570242\n",
      "   3.5160637 ]]\n",
      "MSE Train:  0.0009214297\n",
      "MSE Test:  0.0010404448\n",
      "pred:  [[-0.5103295  -0.39822793 -0.45576447 ... -0.4409626  -0.3216492\n",
      "   3.6098223 ]]\n",
      "MSE Train:  0.001139402\n",
      "MSE Test:  0.0012385452\n",
      "pred:  [[-0.5116746  -0.38328397 -0.45267004 ... -0.43215042 -0.3439588\n",
      "   3.711878  ]]\n",
      "MSE Train:  0.0010476457\n",
      "MSE Test:  0.001157691\n",
      "pred:  [[-0.52011883 -0.39744252 -0.45647958 ... -0.4459799  -0.3573893\n",
      "   3.5862935 ]]\n",
      "MSE Train:  0.0012691268\n",
      "MSE Test:  0.0013744121\n",
      "pred:  [[-0.5039614  -0.39760906 -0.44712138 ... -0.42611235 -0.31782877\n",
      "   3.4920058 ]]\n",
      "MSE Train:  0.0011476277\n",
      "MSE Test:  0.0012552057\n",
      "pred:  [[-0.51517314 -0.39999917 -0.45030808 ... -0.44006395 -0.3491259\n",
      "   3.655727  ]]\n",
      "MSE Train:  0.0011204318\n",
      "MSE Test:  0.0012374714\n",
      "pred:  [[-0.519787   -0.40206087 -0.4541397  ... -0.4256425  -0.33314818\n",
      "   3.5255399 ]]\n",
      "MSE Train:  0.0012639868\n",
      "MSE Test:  0.0013056205\n",
      "pred:  [[-0.5152285  -0.39893842 -0.4536755  ... -0.44656527 -0.36544245\n",
      "   3.5796835 ]]\n",
      "MSE Train:  0.0011222499\n",
      "MSE Test:  0.0012319342\n",
      "pred:  [[-0.5182353  -0.40708953 -0.45693818 ... -0.43738973 -0.3473859\n",
      "   3.6388226 ]]\n",
      "MSE Train:  0.0011463679\n",
      "MSE Test:  0.0012425068\n",
      "pred:  [[-0.510136   -0.37647814 -0.4413677  ... -0.41870487 -0.27947575\n",
      "   3.6909173 ]]\n",
      "MSE Train:  0.0012571833\n",
      "MSE Test:  0.0013415689\n",
      "pred:  [[-0.5075815  -0.40633953 -0.45796752 ... -0.43844038 -0.32320908\n",
      "   3.5751693 ]]\n",
      "MSE Train:  0.0010714118\n",
      "MSE Test:  0.0011382626\n",
      "pred:  [[-0.51728463 -0.36472756 -0.4534461  ... -0.43577412 -0.30924425\n",
      "   3.7461414 ]]\n",
      "MSE Train:  0.0011013101\n",
      "MSE Test:  0.0012062809\n",
      "pred:  [[-0.50493497 -0.37171412 -0.4459402  ... -0.4376536  -0.3475755\n",
      "   3.6300204 ]]\n",
      "MSE Train:  0.0009509241\n",
      "MSE Test:  0.0010542807\n",
      "pred:  [[-0.51206255 -0.39663908 -0.46040067 ... -0.46017417 -0.35576695\n",
      "   3.5917687 ]]\n",
      "MSE Train:  0.0013026248\n",
      "MSE Test:  0.0014079587\n",
      "pred:  [[-0.50412434 -0.37929854 -0.4409204  ... -0.42068103 -0.2973267\n",
      "   3.6930625 ]]\n",
      "MSE Train:  0.0013224338\n",
      "MSE Test:  0.001422453\n",
      "pred:  [[-0.5086639  -0.39879724 -0.45344973 ... -0.42988655 -0.3216187\n",
      "   3.5672398 ]]\n",
      "MSE Train:  0.0009034404\n",
      "MSE Test:  0.0009834283\n",
      "pred:  [[-0.512799   -0.38727692 -0.45491117 ... -0.4476798  -0.3403457\n",
      "   3.690318  ]]\n",
      "MSE Train:  0.0013075862\n",
      "MSE Test:  0.0013931126\n",
      "pred:  [[-0.5058775  -0.36213428 -0.4373561  ... -0.40962476 -0.2793367\n",
      "   3.6672611 ]]\n",
      "MSE Train:  0.0018356103\n",
      "MSE Test:  0.0019418596\n",
      "pred:  [[-0.50505507 -0.37704527 -0.46016282 ... -0.42891377 -0.31828886\n",
      "   3.655656  ]]\n",
      "MSE Train:  0.0010802896\n",
      "MSE Test:  0.0011504077\n",
      "pred:  [[-0.51656896 -0.40250883 -0.46284723 ... -0.43696344 -0.35298255\n",
      "   3.6024377 ]]\n",
      "MSE Train:  0.0010276489\n",
      "MSE Test:  0.0011232388\n",
      "pred:  [[-0.5051     -0.40330386 -0.45425874 ... -0.4466162  -0.32882702\n",
      "   3.703762  ]]\n",
      "MSE Train:  0.0015881209\n",
      "MSE Test:  0.0017037967\n",
      "pred:  [[-0.51435167 -0.40635607 -0.45986313 ... -0.43555528 -0.322995\n",
      "   3.6128585 ]]\n",
      "MSE Train:  0.0017145628\n",
      "MSE Test:  0.001781578\n",
      "pred:  [[-0.512073   -0.3733686  -0.453134   ... -0.44164267 -0.3080422\n",
      "   3.7262635 ]]\n",
      "MSE Train:  0.0012811263\n",
      "MSE Test:  0.0013524519\n",
      "pred:  [[-0.51641506 -0.4034624  -0.4465723  ... -0.44949156 -0.33015275\n",
      "   3.6754615 ]]\n",
      "MSE Train:  0.000920223\n",
      "MSE Test:  0.001012254\n",
      "pred:  [[-0.51870096 -0.40370584 -0.46310034 ... -0.44590637 -0.3069153\n",
      "   3.5735343 ]]\n",
      "MSE Train:  0.0014476432\n",
      "MSE Test:  0.0015784778\n",
      "pred:  [[-0.5130005  -0.3964948  -0.45225412 ... -0.43062174 -0.32425016\n",
      "   3.420544  ]]\n",
      "MSE Train:  0.0008683333\n",
      "MSE Test:  0.00093432923\n",
      "pred:  [[-0.5130355  -0.39711672 -0.4544729  ... -0.43211907 -0.3209362\n",
      "   3.633052  ]]\n",
      "MSE Train:  0.0009292958\n",
      "MSE Test:  0.0010106427\n",
      "pred:  [[-0.5174435  -0.4017375  -0.45081872 ... -0.4341085  -0.3133491\n",
      "   3.5123503 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.0007567971\n",
      "MSE Test:  0.0008605062\n",
      "pred:  [[-0.52314925 -0.41362104 -0.45854643 ... -0.4434143  -0.33183444\n",
      "   3.561757  ]]\n",
      "MSE Train:  0.00074114325\n",
      "MSE Test:  0.00081925705\n",
      "pred:  [[-0.5159909  -0.40448734 -0.45837155 ... -0.437513   -0.32063064\n",
      "   3.5490618 ]]\n",
      "MSE Train:  0.0009316264\n",
      "MSE Test:  0.0010078561\n",
      "pred:  [[-0.50659597 -0.38897678 -0.44882587 ... -0.4391127  -0.33232227\n",
      "   3.6255703 ]]\n",
      "MSE Train:  0.0012384946\n",
      "MSE Test:  0.0013339842\n",
      "pred:  [[-0.51049703 -0.39037597 -0.45251092 ... -0.42560565 -0.3116891\n",
      "   3.5270555 ]]\n",
      "MSE Train:  0.0011312079\n",
      "MSE Test:  0.001213234\n",
      "pred:  [[-0.5117171  -0.40317312 -0.459128   ... -0.447124   -0.32708228\n",
      "   3.7177107 ]]\n",
      "MSE Train:  0.000798999\n",
      "MSE Test:  0.0008686968\n",
      "pred:  [[-0.5126721  -0.41336715 -0.46297562 ... -0.4441358  -0.331828\n",
      "   3.6837695 ]]\n",
      "MSE Train:  0.00093546766\n",
      "MSE Test:  0.0009996883\n",
      "pred:  [[-0.5078197  -0.39641953 -0.45655903 ... -0.43210214 -0.29392827\n",
      "   3.6113703 ]]\n",
      "MSE Train:  0.00086559524\n",
      "MSE Test:  0.0009509186\n",
      "pred:  [[-0.516104   -0.3968858  -0.4651385  ... -0.4394338  -0.33702785\n",
      "   3.6134396 ]]\n",
      "MSE Train:  0.001332352\n",
      "MSE Test:  0.0014284063\n",
      "pred:  [[-0.511515   -0.38352245 -0.45700994 ... -0.4299523  -0.31101424\n",
      "   3.5320826 ]]\n",
      "MSE Train:  0.0011017324\n",
      "MSE Test:  0.0011572898\n",
      "pred:  [[-0.5159959  -0.4040498  -0.46244603 ... -0.44860905 -0.3235616\n",
      "   3.5816567 ]]\n",
      "MSE Train:  0.00079457444\n",
      "MSE Test:  0.00088968175\n",
      "pred:  [[-0.5147239  -0.39093935 -0.45793223 ... -0.44377726 -0.31377977\n",
      "   3.5697346 ]]\n",
      "MSE Train:  0.0011508686\n",
      "MSE Test:  0.00123149\n",
      "pred:  [[-0.5219859  -0.40221262 -0.46322665 ... -0.4443939  -0.32562506\n",
      "   3.515577  ]]\n",
      "MSE Train:  0.0010104453\n",
      "MSE Test:  0.0010638181\n",
      "pred:  [[-0.515085   -0.39392018 -0.44859827 ... -0.4330973  -0.30605692\n",
      "   3.5705156 ]]\n",
      "MSE Train:  0.000775066\n",
      "MSE Test:  0.00087924855\n",
      "pred:  [[-0.5170253  -0.39086446 -0.4539136  ... -0.43080077 -0.31443542\n",
      "   3.511355  ]]\n",
      "MSE Train:  0.00087132\n",
      "MSE Test:  0.0009480571\n",
      "pred:  [[-0.5205239  -0.40621632 -0.46115357 ... -0.44744426 -0.37251794\n",
      "   3.57887   ]]\n",
      "MSE Train:  0.0009289827\n",
      "MSE Test:  0.0010243182\n",
      "pred:  [[-0.5167218  -0.37717625 -0.44956243 ... -0.43132252 -0.30326256\n",
      "   3.5604103 ]]\n",
      "MSE Train:  0.00078500074\n",
      "MSE Test:  0.0008665088\n",
      "pred:  [[-0.5138864  -0.40312287 -0.45667797 ... -0.44625062 -0.32155624\n",
      "   3.6213982 ]]\n",
      "MSE Train:  0.0008605491\n",
      "MSE Test:  0.0009441352\n",
      "pred:  [[-0.511011   -0.3941579  -0.45727915 ... -0.44438103 -0.3127923\n",
      "   3.6180837 ]]\n",
      "MSE Train:  0.0010947415\n",
      "MSE Test:  0.0012081241\n",
      "pred:  [[-0.5015957  -0.37647927 -0.4451754  ... -0.42292684 -0.27943182\n",
      "   3.6005237 ]]\n",
      "Model saved in path: ../models/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Init\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit neural net\n",
    "    batch_size = 256\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "\n",
    "    # Run\n",
    "    epochs = 20\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        # Minibatch training\n",
    "        for i in range(0, len(y_train) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "            # Run optimizer with batch\n",
    "            sess.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "            # Show progress\n",
    "            if np.mod(i, 50) == 0:\n",
    "                # MSE train and test\n",
    "                mse_train.append(sess.run(mse, feed_dict={X: X_train, Y: y_train}))\n",
    "                mse_test.append(sess.run(mse, feed_dict={X: X_test, Y: y_test}))\n",
    "                print('MSE Train: ', mse_train[-1])\n",
    "                print('MSE Test: ', mse_test[-1])\n",
    "                # Prediction\n",
    "                pred = sess.run(out, feed_dict={X: X_test})\n",
    "                print('pred: ', pred)\n",
    "    save_path = saver.save(sess, \"../models/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
